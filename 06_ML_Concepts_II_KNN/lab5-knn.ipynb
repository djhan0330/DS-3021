{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graduation Lab: Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dongju Han"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: \n",
    "Let's build a kNN model using the college completion data. \n",
    "The data is messy and you have a degrees of freedom problem, as in, we have too many features.  \n",
    "\n",
    "You've done most of the hard work already, so you should be ready to move forward with building your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use the question/target variable you submitted and build a model to answer the question you created for this dataset (make sure it is a classification problem, convert if necessary). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Question From Previous Lab:\n",
    " * \"Is there a correlation between institutional type and cohort size?\"\n",
    "\n",
    "### Recreated the Question: \n",
    "* \"How well does my kNN model predict institutional type (Public/Private) based on student retention rate?\"\n",
    "* The Target Variable will be the institutional type\n",
    "\n",
    "I recreated the question so that it is a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3798 entries, 0 to 3797\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   unitid                                3798 non-null   int64  \n",
      " 1   chronname                             3798 non-null   object \n",
      " 2   city                                  3798 non-null   object \n",
      " 3   state                                 3798 non-null   object \n",
      " 4   level                                 3798 non-null   object \n",
      " 5   control                               3798 non-null   object \n",
      " 6   basic                                 3798 non-null   object \n",
      " 7   hbcu                                  94 non-null     object \n",
      " 8   flagship                              50 non-null     object \n",
      " 9   long_x                                3798 non-null   float64\n",
      " 10  lat_y                                 3798 non-null   float64\n",
      " 11  site                                  3779 non-null   object \n",
      " 12  student_count                         3798 non-null   int64  \n",
      " 13  awards_per_value                      3798 non-null   float64\n",
      " 14  awards_per_state_value                3798 non-null   float64\n",
      " 15  awards_per_natl_value                 3798 non-null   float64\n",
      " 16  exp_award_value                       3798 non-null   int64  \n",
      " 17  exp_award_state_value                 3798 non-null   int64  \n",
      " 18  exp_award_natl_value                  3798 non-null   int64  \n",
      " 19  exp_award_percentile                  3798 non-null   int64  \n",
      " 20  ft_pct                                3794 non-null   float64\n",
      " 21  fte_value                             3798 non-null   int64  \n",
      " 22  fte_percentile                        3798 non-null   int64  \n",
      " 23  med_sat_value                         1337 non-null   float64\n",
      " 24  med_sat_percentile                    1337 non-null   float64\n",
      " 25  aid_value                             3797 non-null   float64\n",
      " 26  aid_percentile                        3797 non-null   float64\n",
      " 27  endow_value                           2323 non-null   float64\n",
      " 28  endow_percentile                      2323 non-null   float64\n",
      " 29  grad_100_value                        3467 non-null   float64\n",
      " 30  grad_100_percentile                   3467 non-null   float64\n",
      " 31  grad_150_value                        3467 non-null   float64\n",
      " 32  grad_150_percentile                   3467 non-null   float64\n",
      " 33  pell_value                            3797 non-null   float64\n",
      " 34  pell_percentile                       3797 non-null   float64\n",
      " 35  retain_value                          3535 non-null   float64\n",
      " 36  retain_percentile                     3535 non-null   float64\n",
      " 37  ft_fac_value                          3785 non-null   float64\n",
      " 38  ft_fac_percentile                     3785 non-null   float64\n",
      " 39  vsa_year                              279 non-null    float64\n",
      " 40  vsa_grad_after4_first                 279 non-null    float64\n",
      " 41  vsa_grad_elsewhere_after4_first       279 non-null    float64\n",
      " 42  vsa_enroll_after4_first               279 non-null    float64\n",
      " 43  vsa_enroll_elsewhere_after4_first     279 non-null    float64\n",
      " 44  vsa_grad_after6_first                 279 non-null    float64\n",
      " 45  vsa_grad_elsewhere_after6_first       279 non-null    float64\n",
      " 46  vsa_enroll_after6_first               279 non-null    float64\n",
      " 47  vsa_enroll_elsewhere_after6_first     279 non-null    float64\n",
      " 48  vsa_grad_after4_transfer              270 non-null    float64\n",
      " 49  vsa_grad_elsewhere_after4_transfer    270 non-null    float64\n",
      " 50  vsa_enroll_after4_transfer            270 non-null    float64\n",
      " 51  vsa_enroll_elsewhere_after4_transfer  270 non-null    float64\n",
      " 52  vsa_grad_after6_transfer              270 non-null    float64\n",
      " 53  vsa_grad_elsewhere_after6_transfer    270 non-null    float64\n",
      " 54  vsa_enroll_after6_transfer            270 non-null    float64\n",
      " 55  vsa_enroll_elsewhere_after6_transfer  270 non-null    float64\n",
      " 56  similar                               3579 non-null   object \n",
      " 57  state_sector_ct                       3798 non-null   int64  \n",
      " 58  carnegie_ct                           3798 non-null   int64  \n",
      " 59  counted_pct                           3372 non-null   object \n",
      " 60  nicknames                             310 non-null    object \n",
      " 61  cohort_size                           3467 non-null   float64\n",
      "dtypes: float64(40), int64(10), object(12)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "grad_data = pd.read_csv('https://query.data.world/s/qpi2ltkz23yp2fcaz4jmlrskjx5qnp', encoding=\"cp1252\")\n",
    "grad_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3798 entries, 0 to 3797\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   unitid                                3798 non-null   int64  \n",
      " 1   chronname                             3798 non-null   object \n",
      " 2   city                                  3798 non-null   object \n",
      " 3   state                                 3798 non-null   object \n",
      " 4   level                                 3798 non-null   object \n",
      " 5   Institutional_Type                    3798 non-null   object \n",
      " 6   basic                                 3798 non-null   object \n",
      " 7   hbcu                                  94 non-null     object \n",
      " 8   flagship                              50 non-null     object \n",
      " 9   long_x                                3798 non-null   float64\n",
      " 10  lat_y                                 3798 non-null   float64\n",
      " 11  site                                  3779 non-null   object \n",
      " 12  student_count                         3798 non-null   int64  \n",
      " 13  awards_per_value                      3798 non-null   float64\n",
      " 14  awards_per_state_value                3798 non-null   float64\n",
      " 15  awards_per_natl_value                 3798 non-null   float64\n",
      " 16  exp_award_value                       3798 non-null   int64  \n",
      " 17  exp_award_state_value                 3798 non-null   int64  \n",
      " 18  exp_award_natl_value                  3798 non-null   int64  \n",
      " 19  exp_award_percentile                  3798 non-null   int64  \n",
      " 20  ft_pct                                3794 non-null   float64\n",
      " 21  fte_value                             3798 non-null   int64  \n",
      " 22  fte_percentile                        3798 non-null   int64  \n",
      " 23  med_sat_value                         1337 non-null   float64\n",
      " 24  med_sat_percentile                    1337 non-null   float64\n",
      " 25  aid_value                             3797 non-null   float64\n",
      " 26  aid_percentile                        3797 non-null   float64\n",
      " 27  endow_value                           2323 non-null   float64\n",
      " 28  endow_percentile                      2323 non-null   float64\n",
      " 29  grad_100_value                        3467 non-null   float64\n",
      " 30  grad_100_percentile                   3467 non-null   float64\n",
      " 31  grad_150_value                        3467 non-null   float64\n",
      " 32  grad_150_percentile                   3467 non-null   float64\n",
      " 33  pell_value                            3797 non-null   float64\n",
      " 34  pell_percentile                       3797 non-null   float64\n",
      " 35  retain_value                          3535 non-null   float64\n",
      " 36  retain_percentile                     3535 non-null   float64\n",
      " 37  ft_fac_value                          3785 non-null   float64\n",
      " 38  ft_fac_percentile                     3785 non-null   float64\n",
      " 39  vsa_year                              279 non-null    float64\n",
      " 40  vsa_grad_after4_first                 279 non-null    float64\n",
      " 41  vsa_grad_elsewhere_after4_first       279 non-null    float64\n",
      " 42  vsa_enroll_after4_first               279 non-null    float64\n",
      " 43  vsa_enroll_elsewhere_after4_first     279 non-null    float64\n",
      " 44  vsa_grad_after6_first                 279 non-null    float64\n",
      " 45  vsa_grad_elsewhere_after6_first       279 non-null    float64\n",
      " 46  vsa_enroll_after6_first               279 non-null    float64\n",
      " 47  vsa_enroll_elsewhere_after6_first     279 non-null    float64\n",
      " 48  vsa_grad_after4_transfer              270 non-null    float64\n",
      " 49  vsa_grad_elsewhere_after4_transfer    270 non-null    float64\n",
      " 50  vsa_enroll_after4_transfer            270 non-null    float64\n",
      " 51  vsa_enroll_elsewhere_after4_transfer  270 non-null    float64\n",
      " 52  vsa_grad_after6_transfer              270 non-null    float64\n",
      " 53  vsa_grad_elsewhere_after6_transfer    270 non-null    float64\n",
      " 54  vsa_enroll_after6_transfer            270 non-null    float64\n",
      " 55  vsa_enroll_elsewhere_after6_transfer  270 non-null    float64\n",
      " 56  similar                               3579 non-null   object \n",
      " 57  state_sector_ct                       3798 non-null   int64  \n",
      " 58  carnegie_ct                           3798 non-null   int64  \n",
      " 59  counted_pct                           3372 non-null   object \n",
      " 60  nicknames                             310 non-null    object \n",
      " 61  cohort_size                           3467 non-null   float64\n",
      "dtypes: float64(40), int64(10), object(12)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#I will change the column name \"Control\" to \"Institutional Type\"\n",
    "grad_data.rename(columns = {\"control\": \"Institutional_Type\"},inplace= True)\n",
    "grad_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Institutional_Type\n",
       "Public                    1558\n",
       "Private not-for-profit    1248\n",
       "Private for-profit         992\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_data.Institutional_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retain_value\n",
       "100.0    52\n",
       "66.7     44\n",
       "50.0     39\n",
       "0.0      39\n",
       "75.0     28\n",
       "         ..\n",
       "24.7      1\n",
       "41.5      1\n",
       "40.3      1\n",
       "43.7      1\n",
       "32.0      1\n",
       "Name: count, Length: 649, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_data.retain_value.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Institutional_Type\n",
       "Private    2240\n",
       "Public     1558\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I should combine Private not-for-profit and Private for-profit to Private\n",
    "Private = [\"Private not-for-profit\", \"Private for-profit\"]\n",
    "grad_data.Institutional_Type = grad_data.Institutional_Type.apply(lambda x: \"Private\" if x in Private else \"Public\")\n",
    "grad_data.Institutional_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3798 entries, 0 to 3797\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                Non-Null Count  Dtype   \n",
      "---  ------                                --------------  -----   \n",
      " 0   unitid                                3798 non-null   int64   \n",
      " 1   chronname                             3798 non-null   object  \n",
      " 2   city                                  3798 non-null   object  \n",
      " 3   state                                 3798 non-null   object  \n",
      " 4   level                                 3798 non-null   category\n",
      " 5   Institutional_Type                    3798 non-null   category\n",
      " 6   basic                                 3798 non-null   object  \n",
      " 7   hbcu                                  94 non-null     object  \n",
      " 8   flagship                              50 non-null     object  \n",
      " 9   long_x                                3798 non-null   float64 \n",
      " 10  lat_y                                 3798 non-null   float64 \n",
      " 11  site                                  3779 non-null   object  \n",
      " 12  student_count                         3798 non-null   int64   \n",
      " 13  awards_per_value                      3798 non-null   float64 \n",
      " 14  awards_per_state_value                3798 non-null   float64 \n",
      " 15  awards_per_natl_value                 3798 non-null   float64 \n",
      " 16  exp_award_value                       3798 non-null   int64   \n",
      " 17  exp_award_state_value                 3798 non-null   int64   \n",
      " 18  exp_award_natl_value                  3798 non-null   int64   \n",
      " 19  exp_award_percentile                  3798 non-null   int64   \n",
      " 20  ft_pct                                3794 non-null   float64 \n",
      " 21  fte_value                             3798 non-null   int64   \n",
      " 22  fte_percentile                        3798 non-null   int64   \n",
      " 23  med_sat_value                         1337 non-null   float64 \n",
      " 24  med_sat_percentile                    1337 non-null   float64 \n",
      " 25  aid_value                             3797 non-null   float64 \n",
      " 26  aid_percentile                        3797 non-null   float64 \n",
      " 27  endow_value                           2323 non-null   float64 \n",
      " 28  endow_percentile                      2323 non-null   float64 \n",
      " 29  grad_100_value                        3467 non-null   float64 \n",
      " 30  grad_100_percentile                   3467 non-null   float64 \n",
      " 31  grad_150_value                        3467 non-null   float64 \n",
      " 32  grad_150_percentile                   3467 non-null   float64 \n",
      " 33  pell_value                            3797 non-null   float64 \n",
      " 34  pell_percentile                       3797 non-null   float64 \n",
      " 35  retain_value                          3535 non-null   float64 \n",
      " 36  retain_percentile                     3535 non-null   float64 \n",
      " 37  ft_fac_value                          3785 non-null   float64 \n",
      " 38  ft_fac_percentile                     3785 non-null   float64 \n",
      " 39  vsa_year                              279 non-null    float64 \n",
      " 40  vsa_grad_after4_first                 279 non-null    float64 \n",
      " 41  vsa_grad_elsewhere_after4_first       279 non-null    float64 \n",
      " 42  vsa_enroll_after4_first               279 non-null    float64 \n",
      " 43  vsa_enroll_elsewhere_after4_first     279 non-null    float64 \n",
      " 44  vsa_grad_after6_first                 279 non-null    float64 \n",
      " 45  vsa_grad_elsewhere_after6_first       279 non-null    float64 \n",
      " 46  vsa_enroll_after6_first               279 non-null    float64 \n",
      " 47  vsa_enroll_elsewhere_after6_first     279 non-null    float64 \n",
      " 48  vsa_grad_after4_transfer              270 non-null    float64 \n",
      " 49  vsa_grad_elsewhere_after4_transfer    270 non-null    float64 \n",
      " 50  vsa_enroll_after4_transfer            270 non-null    float64 \n",
      " 51  vsa_enroll_elsewhere_after4_transfer  270 non-null    float64 \n",
      " 52  vsa_grad_after6_transfer              270 non-null    float64 \n",
      " 53  vsa_grad_elsewhere_after6_transfer    270 non-null    float64 \n",
      " 54  vsa_enroll_after6_transfer            270 non-null    float64 \n",
      " 55  vsa_enroll_elsewhere_after6_transfer  270 non-null    float64 \n",
      " 56  similar                               3579 non-null   object  \n",
      " 57  state_sector_ct                       3798 non-null   int64   \n",
      " 58  carnegie_ct                           3798 non-null   int64   \n",
      " 59  counted_pct                           3372 non-null   object  \n",
      " 60  nicknames                             310 non-null    object  \n",
      " 61  cohort_size                           3467 non-null   float64 \n",
      "dtypes: category(2), float64(40), int64(10), object(10)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Change objects to categorical variables (only the ones that are necessary)\n",
    "cat = [\"level\", \"Institutional_Type\"]\n",
    "grad_data[cat] = grad_data[cat].astype(\"category\")\n",
    "grad_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_na = grad_data[\"Institutional_Type\"].isna().any() #False\n",
    "grad_data = grad_data.dropna(subset=['retain_percentile'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "has_na1 = grad_data[\"retain_percentile\"].isna().sum() \n",
    "print(has_na1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unitid: [100654 100663 100690 ... 462354 466921 474881]\n",
      "chronname: ['Alabama A&M University' 'University of Alabama at Birmingham'\n",
      " 'Amridge University' ... 'John Paul the Great Catholic University'\n",
      " 'Chamberlain College of Nursing-Missouri' 'Minneapolis Media Institute']\n",
      "city: ['Normal' 'Birmingham' 'Montgomery' ... 'Baraga' 'Escondido' 'Edina']\n",
      "state: ['Alabama' 'Alaska' 'Arizona' 'New Mexico' 'Arkansas' 'California'\n",
      " 'Colorado' 'Connecticut' 'Delaware' 'District of Columbia' 'Virginia'\n",
      " 'Florida' 'Georgia' 'Hawaii' 'Idaho' 'Illinois' 'Indiana' 'Iowa' 'Kansas'\n",
      " 'Missouri' 'Kentucky' 'Louisiana' 'Maine' 'Maryland' 'Massachusetts'\n",
      " 'Michigan' 'Minnesota' 'Mississippi' 'Montana' 'Nebraska' 'Nevada'\n",
      " 'New Hampshire' 'New Jersey' 'New York' 'North Carolina' 'North Dakota'\n",
      " 'Ohio' 'Oklahoma' 'Oregon' 'Pennsylvania' 'Rhode Island' 'South Carolina'\n",
      " 'South Dakota' 'Tennessee' 'Texas' 'Utah' 'Vermont' 'Washington'\n",
      " 'West Virginia' 'Wisconsin' 'Wyoming']\n",
      "level: ['4-year', '2-year']\n",
      "Categories (2, object): ['2-year', '4-year']\n",
      "Institutional_Type: ['Public', 'Private']\n",
      "Categories (2, object): ['Private', 'Public']\n",
      "basic: ['Masters Colleges and Universities--larger programs'\n",
      " 'Research Universities--very high research activity'\n",
      " 'Baccalaureate Colleges--Arts & Sciences'\n",
      " 'Research Universities--high research activity'\n",
      " 'Associates--Public Rural-serving Medium'\n",
      " 'Baccalaureate Colleges--Diverse Fields'\n",
      " 'Baccalaureate/Associates Colleges'\n",
      " 'Associates--Public Suburban-serving Multicampus'\n",
      " 'Associates--Public Rural-serving Large'\n",
      " 'Associates--Public Rural-serving Small'\n",
      " 'Associates--Public Urban-serving Multicampus'\n",
      " 'Masters Colleges and Universities--medium programs'\n",
      " 'Associates--Private For-profit'\n",
      " 'Theological seminaries- Bible colleges- and other faith-related institutions'\n",
      " 'Masters Colleges and Universities--smaller programs'\n",
      " 'Not applicable- not in Carnegie universe'\n",
      " 'Schools of art- music- and design'\n",
      " 'Associates--Private For-profit 4-year Primarily Associates'\n",
      " 'Other technology-related schools' 'Tribal Colleges'\n",
      " 'Associates--Public Urban-serving Single Campus'\n",
      " 'Doctoral/Research Universities'\n",
      " 'Associates--Public 2-year colleges under 4-year universities'\n",
      " 'Associates--Private Not-for-profit 4-year Primarily Associates'\n",
      " 'Associates--Public Suburban-serving Single Campus'\n",
      " 'Associates--Private Not-for-profit' 'Other health professions schools'\n",
      " 'Schools of business and management'\n",
      " 'Associates--Public 4-year Primarily Associates'\n",
      " 'Associates--Public Special Use' 'Schools of engineering'\n",
      " 'Other special-focus institutions' 'Schools of law']\n",
      "hbcu: ['X' nan]\n",
      "flagship: [nan 'X']\n",
      "long_x: [ -86.568502  -86.80917   -86.17401  ... -117.082401  -90.436221\n",
      "  -93.331491]\n",
      "lat_y: [34.783368 33.50223  32.362609 ... 33.12085  38.70204  44.86618 ]\n",
      "site: ['www.aamu.edu/' 'www.uab.edu' 'www.amridgeuniversity.edu' ...\n",
      " 'www.gcd.edu' 'www.jpcatholic.com/' 'www.mediainstitute.edu/minneapolis']\n",
      "student_count: [ 4051 11502   322 ...  9648   106   488]\n",
      "awards_per_value: [ 14.2  20.9  29.9  11.6  18.3  15.9  15.4  21.5  23.5  13.6  12.3  15.\n",
      "  17.4  11.8  14.5  17.1  18.8  23.8  50.   22.2  19.3  18.1  20.1  15.8\n",
      "  12.8  13.5  15.3  26.1  12.   21.7  16.3  23.7  16.9  19.5   9.   25.\n",
      "  11.3  19.9   5.2  10.7  20.7  17.3  18.5  18.7  13.1  17.7  21.4  13.9\n",
      "  16.6  16.1  16.2  22.9  34.2   5.1  60.4  76.4  24.8  18.4  21.3  12.7\n",
      "  20.2  27.   22.5  20.6  21.   15.2  24.1  22.6  36.1  21.1  10.2   8.6\n",
      "  22.7  23.4  22.1  24.6  23.1  44.1   7.4  27.9  28.   38.3  30.   19.\n",
      "  18.9  10.4  18.6  26.6  23.6  21.2  20.4  33.1  19.8  14.9  20.8  27.7\n",
      "  11.2  26.5  33.4  23.2  31.6  19.7  27.6  32.5  30.5  14.    7.7  32.4\n",
      "  13.8  24.2   9.2  13.2  25.1  25.2  33.5  22.   23.9  26.   26.9  25.8\n",
      "  27.2  25.3  26.8  21.9  26.3  26.7  24.9  31.7  14.7  12.5  39.9  11.\n",
      "  10.1  60.2  17.8  17.2   9.3  17.5   5.5   7.5  12.2  13.4   8.3   8.4\n",
      "  24.   13.3  37.3  48.1  47.   59.3  15.7  10.3   8.8  31.9  12.4  10.6\n",
      "   4.8  16.4  29.8  29.3   6.9  22.3  15.6  14.1   7.1   6.4  24.5  25.4\n",
      "  35.1  28.5   6.6  11.9  28.7  12.9   9.1  20.3  10.8  28.2  29.2  18.2\n",
      "  55.5  48.7  14.3  17.   20.5  17.9  21.8  12.6  19.4  13.7  47.9   8.7\n",
      "  25.6  21.6  40.1  40.    9.9  30.2  33.8  10.5  16.7  11.5   8.2  30.9\n",
      "  66.8  31.3   4.2  45.5  18.   16.   14.4  48.5  32.8  73.6  19.2   6.2\n",
      "   7.3  49.1  12.1  24.4  25.7  54.5  30.8  73.9  41.   28.1  29.7  23.\n",
      "  19.6  22.4  25.9  16.5   1.9  40.2  33.   26.4  22.8  33.7  38.2  27.8\n",
      "  30.7  26.2  45.2  51.5  51.3  36.   27.3  37.2  23.3  40.7  20.   41.2\n",
      "  27.4  15.5  13.   17.6  19.1  16.8  64.1  32.7   9.4  11.7  24.3   9.8\n",
      "  28.8  14.8   8.    8.1   6.8   7.9  36.3  47.4   5.9  24.7  37.6   9.5\n",
      "  60.7  39.8  48.4  45.   28.6  42.5  30.1  32.2  31.4  34.9  27.5  57.2\n",
      "  46.6  38.7  52.2   7.6  32.1  39.7  29.5  27.1  30.6  15.1  50.8  34.7\n",
      "  34.6  34.4  30.4  44.2  41.5  37.   33.9  40.4  35.2  45.7  35.4  42.\n",
      "  53.9  14.6  50.9  39.4  31.8  62.6  29.4  32.   11.1  33.3  56.7  40.6\n",
      "  28.9  31.1  32.9  38.9  46.9  29.1  33.2  28.3  71.4  36.7  31.2  32.6\n",
      "  31.   25.5  37.9  54.7  34.5  39.1   2.7   6.1  39.6   9.7  28.4  50.3\n",
      "   7.2   3.3  37.8  53.1  46.1  53.6  62.7  37.5  51.7  37.7  70.9  36.6\n",
      "  80.4  60.1  29.6  29.   37.1   1.2  45.4   3.6   2.3  10.9   5.   41.1\n",
      "  32.3   4.4  36.8  35.6  55.3   2.5  35.5  31.5  48.8  41.6  41.3  52.7\n",
      "  71.9  11.4  59.7  43.2  42.7  52.4  42.2  36.4  56.9  46.3  61.5   1.8\n",
      "   7.8   9.6  63.   34.   56.5  43.5  35.3  42.4  75.5  38.5  61.9  51.8\n",
      "  75.   61.4   2.6  34.1  34.8  62.9  39.2  40.5  39.3  44.   55.1  77.5\n",
      " 128.7  45.9  36.5  58.1  43.9  35.   58.4  43.6  74.7  58.3  44.6  35.7\n",
      "  40.8  40.9  45.6  46.7  90.8  50.6  54.9  38.1  36.2  34.3  43.7   5.6\n",
      "  50.2  43.8   7.   57.6  54.   59.    0.5  43.4  46.8  37.4  35.9 131.1\n",
      "  43.   54.2  47.3  35.8  30.3  77.    1.1  60.9  49.8  52.5  71.6  44.8\n",
      "  52.3  44.3  45.1  65.2  72.3  65.3  41.4  50.4  42.1  43.1  46.    6.\n",
      "  56.8  41.7   5.3  60.3  38.8   5.4   6.5  48.9  55.2   8.5  41.9  51.4\n",
      "  10.    4.    4.5  57.1]\n",
      "awards_per_state_value: [18.8 17.8 15.9 29.1  3.2 16.3 22.9 34.2  9.1 36.8 21.7 32.8 22.  20.4\n",
      " 36.7 19.6 19.4 23.6 23.2 12.8 34.1 39.3 22.4 25.  13.5 33.7 25.3 24.7\n",
      " 21.8 15.1 12.1 23.9 16.  20.7 24.4 22.6 16.5 28.4 18.1 24.2 34.7 21.5\n",
      " 18.4 32.6 17.2 34.  18.  28.2 21.6 22.7 18.7 55.5 19.  28.6 14.6 24.3\n",
      " 34.4 26.8 28.  23.8 40.4 17.1 26.7 21.1 21.2 17.3 19.3 41.8 22.3 32.\n",
      " 18.5 41.4 19.5 21.9 28.9 16.7 30.2 50.9 22.1 21.4 17.6 38.6 27.1 16.9\n",
      " 20.9 56.7 18.2 21.3 23.7 38.  20.  36.2 24.5 21.  29.3 16.1 27.2 24.9\n",
      " 31.1 27.7 19.7 32.9 39.  15.8 22.2 44.6 20.5 18.3 23.  17.7 22.8 34.9\n",
      " 14.8 13.4 19.9 20.3 25.9 27.6 15.3 19.8 17.9 25.4 41.5 29.2 39.6 15.6\n",
      " 36.4 23.1 25.6 20.1 18.9 23.3 15.5 37.8 15.  35.1 30.1 36.6 17.5 24.\n",
      " 37.3 33.1 11.9 25.1 18.6 58.1 12.4 38.3 42.7 35.9 28.3 59.9 23.4 13.8\n",
      " 13.  11.6 30.3 20.8 31.6 51.4]\n",
      "awards_per_natl_value: [21.5 22.5 16.5 24.6 32.8 25.9]\n",
      "exp_award_value: [105331 136546  58414 ... 105965  52936  74857]\n",
      "exp_award_state_value: [ 75743  92268  42194  17406  24274 103823  97275  30416 160134  21312\n",
      "  35493  25661  75690  25969  25926  47347  82509  25729  53245  44144\n",
      "  31169  23430 125902  79310  71128  26635  21127  62622  44867 188870\n",
      "  57185  76194  95469  62470 112679  26940 114865 151215  18728  46698\n",
      "  71929  25317  34779  23547 108974  57843  43579  21560  50109  59081\n",
      "  12346  63809  96333  57930  45703  40571  56076  38731  40421  99440\n",
      "  33727  90406  27386  74074  75406  85638  73383  30280  27812  48576\n",
      "  65365  36861  81657  35488  31714  53183  15535  65113  60620  27738\n",
      "  64209  16639  44716  72975  42765  15389  21543 102187  54322  18558\n",
      "  40946 107831  17325  32216  38062  72837  62054  19292  55510 184772\n",
      " 145629  55816  49931  66839  53772  54025  40211  76276  32320  71920\n",
      "  76061  43085  26759  62228  49905  40189  21061  14611  86885  56359\n",
      "  33283  45744  99056  51197  83929  61439  61953  40345  59408  35830\n",
      "  21983  23966  54810  72219  60051  34928 123661  39835  42708  58783\n",
      "  47063  49808  65507 113408  76212  23301  24502  67306  41774 113351\n",
      " 108407  59231  54039  37611  44481  71334  37924  58286  74454 148420\n",
      "  89587  28938  72233  61404  49596  35515  43576  74213  42672  79796\n",
      "  29254  76127  55203  37044  39682  16061  40150  48188  21525  78874\n",
      "  58356 110403  54524  26415  81979  40121  81610 115732  67352  47741\n",
      "  34557  83769  49186  69786  28293  46020  70861  63713  56606  23428\n",
      "  62638 106812  76051  33766  20075  61375  22291  84271  40856  54356\n",
      "  47221  18614  18384  56663  52543  39368  21701  40263 101521  95663\n",
      "  49148  32883  59113  30465  67273  34964  68971  27639  65118  78941\n",
      "  15562  80119  69525  29060  44460  32982  73172  42745  34675  63710\n",
      "  56439  20046  92126  16852  60623  24922  34961  28422  56150  89645\n",
      "  52332  37648  41262  35224  38047 155075 144220  15410  43878  50854\n",
      "  55570  33303  38603]\n",
      "exp_award_natl_value: [ 66436 101725  37780  38763  24795  34510]\n",
      "exp_award_percentile: [ 90  97  30  61  96  75  83  51  71  85  72  81  65  80  23  79  58  13\n",
      "  49  34  54  67  15  40  98  76  21  84  37  27   8  57  77  88  43  95\n",
      "  35  92  73  82  89  50  91  63  69  66 100  53  14  24  93  56   1  19\n",
      "   0  32  33  18  20  99  29   7   2  25  44  41   5  36  48  10  42  28\n",
      "   3   4  11  16   6  22   9  78  31  60  68  52  74  26  64  47  87  46\n",
      "  70  59  17  12  39  62  94  38  55  86  45]\n",
      "ft_pct: [ 93.8  72.7  62.7  74.4  91.   90.2  50.   69.4  98.2  57.3  90.5  51.9\n",
      "  56.5  59.   68.9  54.9  49.   55.9  61.2  81.3  45.9  76.2  56.6  33.8\n",
      "  38.   75.5  84.8  61.9  98.3  94.7  84.9  89.8  47.7  81.5  51.2  95.2\n",
      "  65.7 100.   50.3  55.7  94.6  78.2  48.7  67.1  77.5  93.3  80.7  93.6\n",
      "  91.1  52.6  56.   95.5  51.8  46.9  45.7  31.   63.3  11.7  90.3  99.3\n",
      "  35.   89.7  58.3  33.   37.   29.6  34.6  22.7  20.9  31.9  78.7  27.4\n",
      "  62.2  83.8  20.8  27.   35.8  14.2  30.6  30.5  71.5  27.1  84.4  94.9\n",
      "  88.4  91.2  50.7  75.7  67.4  66.8  62.8  78.6  40.8  44.   47.   57.9\n",
      "  92.7  90.   99.4  39.2  43.4  49.8  97.7  38.9  58.6  97.6  59.1  94.1\n",
      "  37.3  53.1  48.1  50.1  42.9  84.7  43.9  37.7  71.4  54.5  12.3  31.2\n",
      "  25.5  31.6  86.9  36.5  78.8  96.6  78.3  47.8  87.7  93.9  96.4  19.5\n",
      "  88.7  88.3  87.9  92.9  68.7  86.6  80.6  86.8  83.1  83.5  80.8  97.2\n",
      "  97.3  97.9  97.8  98.5  98.7  96.5  18.2  34.8  32.5  30.   29.5  95.8\n",
      "  48.2  89.1  38.2  34.4  99.7  68.2  32.1  90.8  24.6  31.4  23.9  34.9\n",
      "  41.5  23.7  32.   46.3  37.9  81.   19.4  32.8  30.3  88.8  35.7  35.5\n",
      "  36.6  82.6  34.7  31.8  45.5  36.2  99.8  77.2  74.9  70.   64.5  73.9\n",
      "  93.4  33.6  38.6  69.7  78.4  69.8  90.7  31.5  16.8  24.1  55.2  39.7\n",
      "  25.1  22.4  17.   24.8  88.2  21.6  62.3  95.6  21.1  97.   33.7  44.3\n",
      "  26.5  24.4  40.2  36.9  79.7  36.   86.1  92.1  46.8  68.1  38.8  98.6\n",
      "  27.9  73.3  97.5  13.   33.5  37.5  97.1  99.1  43.6  80.4  12.   38.5\n",
      "  26.8  26.1  23.5  93.5  26.4  19.1  96.8  84.5  40.1  79.9  25.7  26.9\n",
      "  74.7  44.1  30.4  98.9  46.   45.   37.8  39.6  25.8  92.4  33.9  91.5\n",
      "  65.   73.8  96.1  21.9  34.   16.2  31.1  20.1  90.4  99.2  98.   82.\n",
      "  19.7  59.8  91.8  63.8  43.1  95.1  23.1  70.8  93.   51.3  75.9  59.2\n",
      "  23.   20.3  19.6  49.2  87.8  77.6  32.2  48.5  75.   71.9  85.2  41.\n",
      "  71.8  78.   17.5  91.6  23.8  86.7  31.7  37.6  86.3  90.6  33.3  72.3\n",
      "  39.4  35.1  84.   20.   85.   37.1  80.   99.9  44.7  47.6  37.2  92.\n",
      "  72.4  88.5  93.1  69.3  42.1  92.8  64.7  57.8  76.3  83.4  59.5  76.8\n",
      "  70.6  96.   48.   89.6  93.2  61.6  96.7  28.   94.2  66.3  88.   88.9\n",
      "  91.4  47.5  76.6  64.3  14.3  87.1  92.3  40.9  70.7  67.   81.7  68.5\n",
      "   7.6  80.2  82.5  85.1  74.6  69.2  98.4  53.7  73.5  83.3  36.3  54.2\n",
      "  42.3  52.9  43.   63.2  72.6  28.3  61.5  57.1  38.1  71.   35.3  60.7\n",
      "  48.8  89.9  91.3  70.1  91.9  80.9  74.   65.9  41.4  29.1  82.8  38.3\n",
      "  90.9  89.   53.4  28.7  89.3  72.5  83.2  66.6  37.4  44.2  34.3  65.4\n",
      "  40.6  61.4  96.3  56.8  50.9  73.6  39.3  95.7  56.1  44.5  26.   94.3\n",
      "  43.8  51.7  79.8  99.6  36.8  24.7  94.   40.5  29.2  49.7  41.8  98.8\n",
      "  28.4  64.4  42.5  48.4  75.3  77.8  42.   87.4  54.7  95.3  44.8  86.2\n",
      "  92.2  64.8  47.4  81.4  40.   83.   82.1  32.4  89.2  98.1  58.7  31.3\n",
      "  99.   92.5  78.9  57.4  74.8  76.1  64.9  82.7  50.5  53.   84.2  54.6\n",
      "  59.6  55.3  19.9  57.6  45.1  81.6  32.9  85.5  38.4  29.   82.9  82.4\n",
      "  52.8  52.2  80.5  46.2  44.6  80.3  95.9  46.5  56.4  53.3  57.2  61.\n",
      "  53.5  38.7  55.8  89.5  35.2  67.9  94.5  63.4  62.6  63.6  60.4  40.7\n",
      "  77.9  85.7  54.3  91.7  36.7  74.1  67.8  72.2  79.   76.5  45.6  84.6\n",
      "  51.4  69.6  76.4  58.8  97.4  95.4  56.9  71.2  67.3  64.   59.3  72.8\n",
      "  81.9  67.6  70.3  34.2  94.8  24.9  95.   26.2  79.5  29.3  49.1  60.3\n",
      "  62.9  53.9  58.5  39.9  77.1  25.2  76.9  22.1  85.4  96.9  51.1  76.\n",
      "  83.6  33.2  22.3  85.3  63.7  36.4  70.9  48.9  92.6  79.1  43.7  94.4\n",
      "  42.2  85.9  75.8  47.3  93.7  99.5  50.8  60.8  55.4  56.7  79.4  43.5\n",
      "  58.9  75.6  73.2  73.7  28.5  30.8  50.6  89.4  85.8  20.5  35.4  51.\n",
      "  21.3  34.5  45.4  40.3  55.1  65.8  35.6  49.5  28.1   5.9  45.2  65.2\n",
      "  67.7  60.9  86.5  77.3  76.7  61.8  78.1  80.1  68.8  52.   78.5  81.8\n",
      "  71.1  72.   73.   52.3  85.6  63.1  35.9  70.2  48.6  11.5  69.   58.2\n",
      "  73.1  84.1  56.3  90.1  73.4  82.2  72.9  75.2  62.4  68.   42.8  55.\n",
      "  71.3  47.1  28.6  25.9  24.2  41.7  30.7  28.9  52.5  60.   74.2  29.7\n",
      "  41.6  87.5  33.1  59.7  24.5   8.9  77.4  75.1  87.   58.   57.5  70.4\n",
      "  30.9  66.2  62.   53.2   9.8  62.1  63.   66.1  87.2  69.9  11.   79.3\n",
      "  45.3  83.7  88.1  88.6  39.   86.4  45.8  79.2  44.9  32.6  51.5  46.7\n",
      "  86.   41.3  54.   51.6  87.6  79.6  25.6  87.3  56.2  27.3  49.9  29.9\n",
      "  34.1  24.3  66.9  48.3  13.9  52.4  39.1  27.6  33.4  41.9  59.9  36.1\n",
      "  17.3  81.2  82.3  43.3  57.   66.5  77.7  65.5  26.3  74.3  58.1  50.4\n",
      "  42.6  46.4  53.6  66.   49.6  58.4  63.9  72.1  54.4  59.4  55.5  20.4\n",
      "  26.6  21.5  30.2  71.6  77.   49.3  13.4  10.2  11.8  69.5  40.4  81.1\n",
      "  22.8  23.4  19.    7.1  71.7  18.5  61.1  22.2  46.6  60.6  69.1  54.8\n",
      "  25.3  44.4  15.6  26.7  64.6  32.3  64.2  42.7  64.1  55.6  50.2  46.1\n",
      "  65.1  60.2  27.7  96.2  42.4  17.8  39.8  21.7  67.2  47.9  16.6   4.4\n",
      "  12.8  57.7  52.1  15.9  28.2  28.8  14.9  17.7  10.3  54.1  68.3  66.4\n",
      "  22.   75.4   3.8  13.7  18.   27.5   8.4   6.   18.7   5.2   8.7  53.8\n",
      "  52.7  14.5   8.2  22.9   5.1  65.3   9.4   8.5   6.2  10.   66.7  20.7\n",
      "   5.4  14.4   5.6]\n",
      "fte_value: [ 3906 10032   294 ...    86  4916   143]\n",
      "fte_percentile: [ 33  67  12  40  41  96  21  30  87  47  20  49  55  78  63  53  62  23\n",
      "  39   9  10  74  82  13  42  18   3  59  48  43  38  61   5   6  44  84\n",
      "  17  58  31  68   4  34  16  76  77  46  72  45  11  92   1  70  37  99\n",
      "  71  98  14  66  56  93  51  95  50   8  91  79  90  89  25  75  60  64\n",
      "  26  29  27  36  15  22  97  88  86  94  85  35  80  83  81  69   7  52\n",
      "  28  19  54  65  24  73 100  32  57   2   0]\n",
      "med_sat_value: [ 823. 1146.   nan 1180.  830. 1171.  970. 1215. 1177.  999. 1036. 1023.\n",
      "  950. 1040. 1058. 1070. 1028.  924. 1153. 1064. 1100.  882.  937. 1008.\n",
      " 1145. 1106. 1050. 1094. 1045. 1077. 1142. 1156.  842. 1088.  974. 1139.\n",
      " 1011. 1267. 1144. 1090. 1057.  930. 1001.  989. 1098. 1123.  984. 1534.\n",
      " 1108. 1242.  901.  917.  888. 1014.  845.  920. 1021.  910. 1012.  871.\n",
      "  918.  945. 1350. 1192. 1122. 1289. 1078. 1276. 1212. 1087. 1080. 1208.\n",
      "  734. 1020.  986. 1397.  979. 1483. 1035.  926. 1104. 1202. 1151.  928.\n",
      "  972. 1303. 1002.  951. 1017. 1172. 1235. 1155. 1454. 1135. 1228. 1061.\n",
      "  998. 1161. 1039. 1030. 1294. 1364. 1115. 1006.  980. 1137. 1380. 1243.\n",
      " 1193. 1043.  987.  939. 1073. 1068. 1323. 1298. 1127. 1231. 1049.  973.\n",
      " 1029.  967. 1005.  923. 1233. 1053. 1034.  865. 1102.  921. 1240. 1387.\n",
      " 1497.  890. 1178.  841. 1258. 1118. 1297. 1398. 1081. 1062.  812.  940.\n",
      " 1175. 1026. 1138.  802. 1105.  947. 1096. 1060.  884. 1154. 1272. 1010.\n",
      " 1332. 1143.  932. 1084. 1199. 1168.  904.  955. 1075.  863.  908.  922.\n",
      "  897.  887.  825.  997.  946.  880. 1186.  957.  896. 1173. 1363. 1352.\n",
      " 1126. 1247.  840.  995.  990. 1131.  778. 1013.  847.  954. 1024. 1000.\n",
      " 1033.  982.  891.  977.  936. 1079. 1163.  892. 1504. 1019. 1092. 1241.\n",
      " 1252. 1110. 1157.  996.  850. 1195.  964. 1046. 1458. 1048. 1031. 1085.\n",
      " 1032. 1318. 1047.  855. 1262. 1147. 1130. 1054. 1018.  934. 1004.  962.\n",
      " 1198.  943. 1083. 1450.  988. 1310.  981.  895. 1141. 1214. 1095. 1158.\n",
      " 1089. 1166. 1182. 1119.  969. 1357. 1086.  956. 1015. 1116. 1113.  985.\n",
      " 1268. 1009.  860. 1140.  976.  909.  952. 1213. 1007. 1162.  968. 1072.\n",
      "  808. 1341. 1423. 1343.  960. 1003.  886. 1042.  963. 1418. 1194. 1209.\n",
      "  893. 1221.  885. 1434. 1234. 1375. 1279. 1347.  991.  931. 1501. 1065.\n",
      " 1132. 1503. 1051. 1394. 1149. 1133. 1428. 1399. 1109. 1439. 1016. 1183.\n",
      " 1204.  780. 1206.  993.  927. 1069. 1406. 1125. 1224. 1270. 1044. 1290.\n",
      "  983. 1165.  851. 1159.  666. 1082.  864. 1263. 1164. 1237. 1474. 1107.\n",
      " 1112.  925. 1091. 1446.  975.  965.  835.  949.  877.  900. 1120.  916.\n",
      "  905. 1063. 1495. 1038. 1210. 1059.  913. 1121. 1305. 1200. 1340. 1101.\n",
      " 1187. 1370. 1471.  912. 1358. 1422. 1225. 1160.  838.  899.  894. 1384.\n",
      " 1331.  907.  874. 1052.  919.  915. 1366. 1232. 1353. 1093. 1253. 1056.\n",
      " 1274. 1129. 1097. 1313. 1217.  777. 1444.  849. 1067.  826.  723.  941.\n",
      "  961.  902. 1190. 1066.  859. 1229.  878.  853.  749. 1136.  889. 1027.\n",
      " 1377. 1181. 1285. 1328. 1071. 1354.  836. 1124. 1176. 1037.  935. 1025.\n",
      " 1371. 1334. 1306. 1432.  948. 1197. 1041. 1117. 1282.  944. 1400.  933.\n",
      "  959. 1283. 1322. 1246.  861.  942. 1442. 1316. 1425. 1076. 1239.  873.\n",
      " 1259. 1055.  938.  789.  854. 1022.  716.  760. 1288.  756. 1248. 1174.\n",
      " 1475. 1216.  903.  953.  775. 1302.  832.  994. 1277. 1134. 1391.  883.\n",
      "  868. 1099.  879.  837. 1220. 1362.  811.  750. 1392. 1114. 1327.  971.\n",
      " 1227. 1244. 1466. 1211.  966.]\n",
      "med_sat_percentile: [  0.  84.  nan  89.   1.  88.  26.  93.  81.  28.  57.  37.  19. 100.\n",
      "  51.  65.  50.   9.  77.  64.  20.   5.  12.  31.  83.  80.  59.  63.\n",
      "  45.  68.  74.  86.   2.  72.  41.  21.  75.  62.  71.  29.  32.  24.\n",
      "  67.  95.  11.   6.  46.  48.  10.  18.  99.  90.  98.  69.  97.  92.\n",
      "  36.  25.  96.  23.   7.  42.  66.  76.  91.  16.  34.  87.  73.  52.\n",
      "  38.  78.  44.  39.  40.  58.  27.  61.  94.  47.  49.  15.  70.  53.\n",
      "  13.  85.  60.   4.  14.  82.  17.  33.  56.  30.  22.  55.  43.  79.\n",
      "   8.  35.   3.  54.]\n",
      "aid_value: [7142. 6088. 2540. ... 9395. 3291. 3434.]\n",
      "aid_percentile: [ 72.  50.   1.  63.  74.  94.  82.  10.  88.  80.  62.   8.  70.  76.\n",
      "  15.  77.  19.  36.  27.  57.  64.  52.  78.  13. 100.  23.  40.  79.\n",
      "  16.  75.  45.  54.  47.  35.  83.  55.  11.  18.  28.  34.  22.   7.\n",
      "  37.   4.  41.  86.   2.  44.  33.  95.  65.  56.  17.  26.  85.  38.\n",
      "  43.   6.  24.  89.  59.  66.  81.  73.  48.  91.  25.  92.  58.  60.\n",
      "  96.  29.  32.  51.  53.   3.  84.  39.  71.  90.  87.  99.  98.  67.\n",
      "  69.  30.  20.  12.  49.   9.   5.  14.  61.  97.  21.  46.   0.  68.\n",
      "  93.  42.  31.  nan]\n",
      "endow_value: [   nan 24136.   302. ...   935.   580.  6054.]\n",
      "endow_percentile: [ nan  93.   1.  81.  84.  90.  22.  79.  92.  70.   5.  37.  18.  46.\n",
      "   4.  73.  33.  20.  75.   2.  97.  34.  43.  62.  27.  51.  19.   6.\n",
      "  82.  63.  47.  53.  21.  49.  83.  72.  31.  87.  60.  50.  24.  12.\n",
      "  78.  95.   7.  30.   9.  11.   8.  29.  35.  89.  71.  80.   3.  14.\n",
      "  54.  58.  52.  28.  65.  99.  44.  16.  32.  68.  15.  96.  85.  13.\n",
      "  86.  98.  42.  23.  25.  55.  88.  74.  38.  59.  40. 100.  57.  61.\n",
      "  76.  36.  69.  67.   0.  17.  10.  41.  91.  94.  77.  64.  39.  56.\n",
      "  66.  48.  26.  45.]\n",
      "grad_100_value: [ 10.   29.4   0.   16.5   8.8  42.7   7.7   9.9  37.6  53.2   7.2   9.8\n",
      "   5.3   8.3   9.5  10.6   7.4   2.3  11.9  30.4  15.4  10.1  13.6   1.8\n",
      "   6.2  38.   18.4  17.9  13.2  23.1   6.   32.9  23.8   2.2  12.3  18.8\n",
      "  17.1  15.8  19.   48.9   2.    4.3   7.   14.1  47.1   8.   16.9  82.4\n",
      "  19.8  13.3  16.7   6.3   8.7   4.1  25.   21.9   4.    nan  37.5  37.7\n",
      "  10.2  39.9  18.3  20.   36.8   5.5  24.1  32.4   7.5  18.1  30.2   5.4\n",
      "   4.8   3.3  26.   23.2  33.3  15.2   6.7   9.4  28.1  25.1  12.6  11.8\n",
      "   4.5  43.4  36.7   5.6  24.   18.7  20.6  10.3   8.4  20.5  18.9  17.8\n",
      "  11.4  40.4  63.3  55.4   2.5  20.4  12.1  48.1   9.3  13.1  34.3  14.3\n",
      "  20.2  14.2  12.5   4.9  11.1  24.2   5.2  13.5  17.4   8.6  60.4  30.7\n",
      "   5.9  65.2  48.8  35.3  10.7   6.8  40.9  31.2  82.3  61.3  29.   15.\n",
      "  18.2   3.8  13.7  10.8   8.2  72.2  51.3  67.6  69.   41.   56.2  67.9\n",
      "  50.1  44.6  40.   51.5  42.6   5.    8.1   7.1   5.7  59.4  53.7  83.6\n",
      "  31.5   4.6   6.9  11.7   3.7  45.1   4.2  15.7  36.   10.5  95.8  47.5\n",
      "  17.7  50.7   4.4  42.8   6.4   8.5   7.8  85.7  28.   30.5  31.1  24.7\n",
      "  52.4   3.1  16.8  68.8  39.   40.3  38.6  53.3  21.1  29.7   7.6   1.2\n",
      "   7.9   4.7  47.8  20.1  66.8  70.5  10.9   3.6  53.    6.5  51.7   9.7\n",
      "  63.9  52.2  36.5  82.8  52.   27.3  78.8  23.6  39.8  70.3  73.   61.7\n",
      "  92.8  54.4  63.4   2.4  15.5 100.   32.7  64.6  22.   61.9  12.7  56.6\n",
      "  30.9  43.9   3.5  36.2  14.6  76.9  80.2  55.2  50.4  25.9  64.1  78.2\n",
      "  10.4  72.7  21.4  45.8  26.9   9.1  71.9  62.9   6.6  11.5  25.5  28.4\n",
      "  45.5  16.1  26.5   8.9  44.3  23.7  79.2  30.1  23.3  31.3  41.2  82.5\n",
      "  37.   12.8  31.8  38.7  26.4  66.5  17.3  32.2  19.7  25.4  46.6  15.9\n",
      "  14.7  42.5  63.   33.9  22.5  20.8  79.3  68.3  78.9   2.8  50.8   2.7\n",
      "  30.8  44.2   1.6   2.6  50.   26.1  72.4   2.1  81.4   1.   86.2  21.\n",
      "  89.6  13.8  68.4  29.6  31.4  75.9  41.8  75.6  88.   39.6  14.9  26.8\n",
      "  21.6  22.7  32.6  23.   13.   35.9  58.9   1.1  33.6  15.1  46.3   9.2\n",
      "  28.6  62.5  62.6  16.   22.9  47.   44.4  80.5  45.   20.7  29.3  24.3\n",
      "  59.3  70.8  50.9  27.4  21.2  19.3  56.   60.8  35.6  27.9  56.4  50.6\n",
      "  19.4   1.7  66.1  73.8  13.9  21.5  15.3  83.8   1.3  38.8  56.8  61.5\n",
      "  21.7  44.   28.5  54.7   3.9  46.7  33.   59.9  35.2  58.3  17.2  41.5\n",
      "  18.6   1.5  35.4  24.9  53.6  12.   32.3  73.6  43.6  33.7  54.9  87.9\n",
      "   0.9   3.2   1.4  31.9  44.8  36.6  54.2  11.2  59.1  29.9  37.9  72.1\n",
      "  55.8  30.6  46.4  32.1  71.   58.4  59.7  48.   56.7  77.4  51.1  39.1\n",
      "  34.   39.3  41.6  76.4  24.6  27.   50.3  30.   23.4  27.8  11.   48.5\n",
      "  38.5  74.5   9.   35.1  46.9  74.2  59.   52.8  53.1  54.5  54.1  42.\n",
      "  19.5  22.2  77.1  76.3  89.8  40.6  66.3  35.7  49.4  67.4  64.8  33.4\n",
      "  57.9  63.5  42.9  61.6  58.8  61.1  53.5  17.5  80.8  25.3  19.6  26.6\n",
      "  40.2  47.6  66.6  47.9  65.7  27.6  55.3  15.6  16.6  43.   38.9  14.8\n",
      "  26.7  29.1  45.9  25.7  40.8  35.8  33.1  37.8  16.2  43.3  62.2  60.3\n",
      "  24.4  30.3  44.9  45.7  56.3  28.3  80.4  46.1  23.9  49.2  22.1  16.4\n",
      "  67.5  47.7  34.6  63.2  77.3  18.   75.    7.3  13.4  16.3  62.3  27.2\n",
      "  50.5  87.6  89.3  49.3  49.1   2.9  45.2  12.9  86.9  26.2  79.4  66.7\n",
      "  61.4  45.3  71.3  55.6  42.1  63.6  89.5  70.2  84.3  81.1  88.5  66.4\n",
      "  79.6  28.7  75.5  35.   61.8  79.7  51.4  65.   20.3  33.5  58.1   9.6\n",
      "  86.5  89.   34.7  58.7  47.3  48.4  83.5  51.9  42.2  38.3   5.1  57.\n",
      "  27.5  38.4  36.4  81.8  87.2  84.2  49.8  71.1  46.   34.2  64.4  17.6\n",
      "  57.1  20.9  12.4  72.5  75.8   5.8  24.8  36.9  21.3  38.1  59.6  84.7\n",
      "  83.1  21.8  29.2  19.1  29.8  22.4  14.   12.2  19.9  63.8  26.3  72.3\n",
      "  34.9  24.5  54.3  85.1  14.5  25.2  53.8  49.6  43.8  60.5  60.7  64.\n",
      "  88.2  51.6  49.7  51.   41.4  54.6  32.8  52.3  54.   27.1  37.3  46.5\n",
      "  63.7   3.   14.4  22.3  32.   34.4  87.8  50.2  44.5   0.5  52.5  60.2\n",
      "  81.9  57.8  40.1  86.6  85.6  67.7   1.9   3.4  19.2  18.5  11.3  76.\n",
      "  74.   49.5  80.   69.2  85.   82.1  62.7  59.8  70.   11.6  32.5  64.9\n",
      "  76.6  53.4  36.1  82.7  55.7  64.7  68.7  81.5  68.5  62.1  89.7  81.\n",
      "  60.   35.5  39.2  89.9  87.1  76.7  49.   57.6  31.7  28.9  80.6  25.6\n",
      "  57.4  41.3  51.8  22.6  29.5  23.5  22.8  48.3  67.3   0.7  77.8  65.4\n",
      "  27.7  74.1  58.5  47.4  33.8  28.2  43.7  39.4  58.6  33.2  34.8   0.3\n",
      "  67.   42.3  69.8  70.9  48.2  34.1  80.7  87.3  31.   74.3  68.6  90.7\n",
      "  83.2  86.1  40.7  66.2  70.6  79.8  91.1  57.7  25.8  60.9  55.1  84.6\n",
      "  53.9  37.2  64.3   6.1  68.2  17.   42.4  45.6  70.4  75.2  56.1  88.8\n",
      "  73.9  73.4  75.4  37.1  84.4  77.7  82.9  28.8  54.8  45.4  52.6  31.6\n",
      "  90.3  86.7  87.5  57.2  55.5   0.8  69.5  38.2  60.1  41.9  65.8  56.9\n",
      "  60.6  86.3  37.4  85.9  71.4  55.9  78.6  57.5  41.7  57.3  55.   76.1\n",
      "  73.2  66.9  39.7  99.2  52.9  40.5  46.2  34.5  83.3  39.5   0.6  99.\n",
      "  97.4  97.8  95.3  93.8  62.4  65.6  69.1  61.2  72.9  68.1  93.2   0.4\n",
      "  62.8  77.6  75.7  58.   52.7  89.2  67.2  76.8  93.3  69.4  63.1  78.5\n",
      "  51.2  72.   69.7]\n",
      "grad_100_percentile: [ 15.  67.   0.  34.  11.  86.  39.  80.  37.   4.  10.  44.  50.   5.\n",
      "  38.  61.  55.  30.  72.  16.  68.   3.  32.  42.  81.  66.  88.   2.\n",
      "  20.  12.  77.  17.  82.  60.  18.  36.  26.  58.  94.  84.  23.   9.\n",
      "  54.  nan  53.  48.  40.  28.  59.  74.  69.  27.  21.  41.  25.  29.\n",
      "   6.  51.  78.  89.  45.  79.  46.  24.  71.   7.  85.  62.  49.  70.\n",
      "  14.  64.  22.  19.  13.  47.  56.  31.  35.  99.  91.  98.  83.  93.\n",
      "  90.  43.  76.  95.  73.  52.  96.  33.   1.  87.  57.  65.   8. 100.\n",
      "  63.  92.  75.  97.]\n",
      "grad_150_value: [ 29.1  53.5  66.7  48.4  25.2   9.1  27.1  67.9  61.9  13.4  13.9   5.3\n",
      "  12.9  10.   22.9  14.4  14.9  19.5  24.8  22.2  43.2  15.4  30.8  29.5\n",
      "   6.5  13.3  40.5  18.5  29.8  20.6  24.9  21.6  49.3  44.9  12.7  32.2\n",
      "  24.   36.8  23.4  25.4  34.3  11.   69.2  11.3   8.2  33.2  56.3  26.2\n",
      "  82.4  32.7  35.5  43.8  27.8  37.3  12.2  40.   21.9  19.2  68.4  63.\n",
      "   nan  42.9  59.5  17.5  61.4  33.3  18.3  20.   22.1  59.1  30.4  70.6\n",
      "  62.8  12.5   6.2  18.1  10.7  10.8  15.9   6.8  69.5  37.7  69.1  17.2\n",
      "  15.1  16.   47.4  65.   18.   16.7  21.4   8.6  49.7  60.1  25.8  35.\n",
      "  35.7  40.7  22.   41.5  37.8  12.   19.7  62.2  28.6  69.6  65.4   8.1\n",
      "  20.4  23.8  60.2  23.3  48.3  27.6  45.   24.5  12.6  39.4  10.4  41.6\n",
      "  24.1  26.7  26.9  60.4  61.2  64.4  64.9  78.3  68.2  36.5  27.4  58.1\n",
      "  61.8  93.1  70.   69.7  39.5  52.   41.1  52.4  56.1  29.4  48.6  38.1\n",
      "  60.3  45.8  91.   81.3  85.8  90.3  66.2  80.7  72.7  44.6  62.4  57.5\n",
      "  58.7  28.8  24.3  13.5  25.6  21.   76.1  62.6  41.2  30.2  31.3  92.5\n",
      "  16.4  31.2  48.1  23.5  24.6  23.6  32.   52.9  30.   97.1  79.7  28.7\n",
      "  54.1  25.   19.3  22.7  22.5  90.8  31.   39.   31.6  34.9  71.4  17.3\n",
      "  81.2  22.3  48.8  43.7  59.3  63.3  33.1  16.2  75.8  58.9  10.1  18.8\n",
      "  53.6  11.7  30.1  70.5  73.5  78.7  78.9  29.9  40.8  15.5  61.6  28.\n",
      "  17.4  23.7  28.9  65.6  21.7  36.   76.7  66.8  38.5  47.9  87.8  37.1\n",
      "  57.3  89.6  36.9  19.8  80.4  82.1  72.1  95.7  54.4  23.   73.    6.7\n",
      "  18.7  25.3  34.8  14.  100.   30.3  75.   64.3  45.5  69.   25.1  42.5\n",
      "  53.   22.4  36.2  35.6  84.   84.1  65.1  47.2  59.6  53.9  54.2  52.3\n",
      "  91.5  17.9  50.   91.2  79.5   0.   62.3  85.3  15.8  19.   13.1  28.3\n",
      "  46.9  44.7  20.5  53.4  53.3  41.3  46.   50.8  87.2  32.5  82.5  63.8\n",
      "  25.9  20.2  31.8  51.9  26.4  77.5  36.6  28.4  26.   34.5  40.9  35.9\n",
      "  46.4  55.7  63.4  21.1  39.2  42.4  26.6  83.5  83.4  50.7   8.9  60.6\n",
      "   8.3  13.   54.7  56.2  13.8  76.3  69.8  52.1   7.9  49.4  86.3  10.3\n",
      "  44.5  97.8   9.2  37.2  81.7  21.8  38.   80.   68.5  50.9  80.8  77.6\n",
      "  33.9  58.4  29.   67.2  56.4  41.   63.1  90.1  88.4  51.6  33.6  36.7\n",
      "  58.2  76.9  86.5  80.5  24.4  38.2  14.3  67.7  62.9  43.3  33.8  40.6\n",
      "  55.6  47.8  67.   45.9  63.2  38.3  64.1  38.4  37.5  32.3  39.9  32.8\n",
      "  42.3  72.   73.8  24.7  48.5  38.9  20.1   6.   18.2  44.8  15.3  16.3\n",
      "  30.6  20.7   8.7   7.7  82.2  35.8  37.   50.5  53.2  67.5  52.8  43.4\n",
      "   9.5  22.6  53.8  62.   20.9  46.1  28.2  68.3  31.5  67.6  32.1  27.\n",
      "  40.2  63.9  45.7  36.4  56.5  39.6  15.2  12.1  11.8  66.3  58.5  66.5\n",
      "  49.1  18.4  54.   78.4  57.6  27.2  45.1  75.6  25.7  92.7   8.4   8.8\n",
      "  10.6  74.   60.7  74.2  32.4   4.8  56.7  52.5  83.9  78.1  23.2  63.6\n",
      "  62.5  71.6  16.8  46.2  42.2  48.7  71.   58.3  84.3  77.4  15.   51.\n",
      "  34.   94.2  20.3  56.8  50.4  46.6  26.5  51.2  41.4  56.6  47.1  43.1\n",
      "  60.   23.9  44.   21.5  14.7  86.7  10.2  59.7  65.5  73.9  27.3   8.\n",
      "  79.2  57.1  70.3  60.5  71.9  41.8  27.9  77.   77.1  70.7  94.9  29.7\n",
      "  72.8  51.5  71.2  58.6  70.1  68.7  52.7  44.4  69.9  46.8  48.   47.\n",
      "  85.7  68.1  17.8  60.9  76.   24.2  58.   72.9  61.3  41.9  29.6  59.2\n",
      "  39.1  55.3  43.6  33.4  13.7  49.6  59.9  42.7  11.1  33.5  39.8  61.5\n",
      "  61.7  82.   43.5  21.2  19.4  11.2  37.9  38.7  30.5  47.6  53.1  72.2\n",
      "  34.2  50.3  11.5  59.   11.4  30.9  81.5  66.9  32.6  49.9  54.9  37.4\n",
      "  42.   40.3  33.   10.5  93.   93.3  29.2  45.2  12.3  55.1  73.6  55.4\n",
      "  51.4  35.1  15.6  62.7   5.1  37.6  35.2  10.9  14.1  21.3  46.5  66.4\n",
      "  84.4   2.9  64.6  33.7   6.3  79.3  71.8  95.8  90.7  55.5  14.6  87.3\n",
      "   6.6  91.3  84.5   2.5  80.9  57.8  40.4  50.6  66.1  97.5  91.4  54.3\n",
      "  81.9  34.6  82.6  31.7  12.4  45.6  44.2  86.1  68.6  49.   84.8  54.8\n",
      "  92.2  54.5  95.4   9.   36.1  55.8  42.1  48.9  60.8   5.5  17.6  90.\n",
      "  65.8  51.8   9.6  17.1  57.2  92.1  46.3  76.8  82.3  31.1  87.4  75.4\n",
      "  85.1  58.8  15.7  81.6  55.2  87.1  75.1  42.8  35.4  25.5  61.1  49.5\n",
      "  39.7  72.3  19.6  57.9  14.5  67.3  51.3  31.4  71.7  64.5  26.8  94.\n",
      "  59.4  67.4  16.9  75.9  68.   40.1  23.1  90.9  94.7  44.1  79.9  56.\n",
      "  27.5  16.6  74.5  16.5  68.8   7.8  47.3  57.7  28.5  96.9  79.4  78.6\n",
      "  50.1  19.9   7.3   7.1   3.5   7.2   3.4  89.7   9.9  11.9  34.1  92.9\n",
      "  79.   62.1  73.1  87.7  76.2  48.2  59.8  73.7  44.3  64.7  52.2  26.3\n",
      "  83.7  18.6  38.6  84.9  85.2  66.6  79.6  85.9  42.6  65.9  77.9  81.1\n",
      "   2.2  47.7  88.   93.6  81.    6.1  28.1  17.7  16.1  52.6  11.6  26.1\n",
      "   7.   13.6   7.5  51.7  14.8  29.3  51.1  35.3   7.6  70.9  13.2  72.6\n",
      "  63.5  56.9   4.4  81.4  75.3  20.8  89.1  81.8  18.9  55.   27.7  88.7\n",
      "  74.1  83.2  77.3  46.7  71.3   3.2  22.8  54.6   0.6  92.3   9.7  41.7\n",
      "  75.5  78.8  53.7   9.3  84.6  85.6  83.6  38.8  88.3  50.2  70.4  69.4\n",
      "  55.9  49.8  83.3  91.7  64.   64.8  71.5  78.5  74.7  93.4  34.4  72.4\n",
      "  79.1  43.9  76.5  45.3  94.5  85.    9.4  68.9  30.7   5.6   6.9  86.8\n",
      "   7.4  47.5   5.4  17.    5.7  87.5   5.9  91.8  82.8  66.    3.8  86.\n",
      "  43.   39.3   4.9  91.1   4.3  57.4  78.   74.8  89.9  14.2  32.9  64.2\n",
      "  90.2  65.3  78.2  76.6  69.3  77.8  70.2  73.2  76.4   5.8  67.1  99.2\n",
      "  82.9  71.1  65.7  84.2   2.   65.2  99.   97.4  19.1   4.2  95.3   3.7\n",
      "   4.7  95.2  67.8  75.7  72.5  79.8  98.6  73.3   8.5  89.2  82.7]\n",
      "grad_150_percentile: [ 14.  66.  72.  54.   9.  85.   8.  12.  87.  64.  23.   2.   1.  21.\n",
      "  10.   6.  27.  28.  47.  41.  30.  18.  80.  22.  43.  15.  52.  67.\n",
      "   5.  39.  46.  20.  63.  16.  61.  89.  13.  76.   7.  91.  86.  24.\n",
      "  25.  40.  70.  56.  nan  81.  79.  65.  42.  34.  58.  17.  60.  94.\n",
      "  55.  71.  37.  29.  33.  35.  77.  57.  48.  51.  75.  31.  19.  11.\n",
      "  73.  50.  69.  74.  98.  32.  36.  49. 100.  96.  99.  83.  95.  78.\n",
      "  53.  82.  84.  97.  62.  93.  45.  59.  38.  92.  88.  90.  44.  68.\n",
      "  26.   0.   3.   4.]\n",
      "pell_value: [ 71.2  35.1  68.4  32.8  82.7  21.1  65.1  40.1  16.9  21.4  61.2  83.6\n",
      "  71.3  51.2  48.9  58.2  60.   55.5  50.2  76.9  63.7  43.   58.7  46.1\n",
      "  52.8  35.8  40.3  47.9  68.2  56.   57.5  44.2  82.3  50.3  41.4  52.3\n",
      "  41.9  62.8  50.7  64.5  70.1  63.5  14.9  75.   52.2  57.4  37.4  33.3\n",
      "  60.9  74.3  96.6  61.   47.6  58.4  24.7  23.5  18.3  27.9  66.   20.9\n",
      "  73.   84.3  66.1  33.8  58.   32.7  53.1  46.4  83.5  30.8  19.8  28.8\n",
      "  38.1  52.6  77.9  51.5  33.7  37.3  68.   47.7  82.2  37.8  29.4  47.3\n",
      "  52.4  49.   61.8  45.5  25.6  22.   50.5  48.1  38.6  31.4  71.1  46.2\n",
      "  24.3  69.9  31.6  45.6  64.7  64.1  39.4  45.3  38.2  44.3  41.6  60.3\n",
      "  63.3  26.3  53.   17.9  31.8  61.5  27.   37.   70.9  39.1  67.2  72.8\n",
      "  39.6  58.6  61.9  38.9  52.7  51.   32.2  42.4  24.2  70.6  28.6  51.1\n",
      "  36.9  39.   49.4  31.   42.8  49.3  24.8  47.8  32.4  10.6  25.8  32.3\n",
      "  57.7  44.   54.1  40.6  48.5  43.2  36.2  56.4  42.7  38.   44.6  71.6\n",
      "  40.7  33.4  37.6  15.7  22.8  47.1  17.6  25.5  36.8  20.3  51.9  25.\n",
      "  32.5  11.6  17.5  39.9  22.7  20.2  16.8  26.   26.5  15.9  45.4  57.8\n",
      "  13.9  27.3  31.9  31.5  35.3  32.1   8.6  57.6  24.9  23.3  41.   27.7\n",
      "  13.1  78.9  88.9  75.9  73.7  76.1  51.6  75.5  56.2  12.5  30.7  31.3\n",
      "  46.5  41.1  22.4  22.6  20.1  48.2  34.8  37.1  30.5  27.1  59.9  19.2\n",
      "  65.4  57.3  36.3  34.6  24.6  22.3  46.7  12.   25.3  13.   36.4  30.9\n",
      "  26.7  69.   74.5  59.8  26.8  61.4  42.   21.3  16.1  19.6  49.9  43.9\n",
      "  11.5  15.8  28.1  20.8  84.4  10.4  38.7  29.2  14.   33.6  18.6  18.1\n",
      "  88.3  88.1  47.4  19.7  39.5  70.8  75.2  67.6  21.9  13.2  65.5  40.8\n",
      "  30.6  25.2  29.7  62.5  49.1  23.1  35.7  80.8  95.   41.7  19.1  29.3\n",
      "  15.4  35.5  58.9  41.5  42.5  50.9  27.8  17.2   9.8  23.7  45.8  25.7\n",
      "  44.4  39.3  80.   76.3  40.2  38.5  30.   60.2  48.6  74.2  72.9  83.1\n",
      "  34.2  41.3  96.5  58.1  37.9  54.3  26.4  15.3  53.9  46.6  62.9  33.5\n",
      "  36.5  43.1  14.3  15.   18.4  28.4  12.7  11.9  49.6  15.6  12.3  28.5\n",
      "  49.2  13.6  13.3  44.9  68.6  64.8  60.4  51.8  77.6  20.   50.6  62.7\n",
      "  37.7  51.4  70.   23.4  84.1  64.4  40.   39.8  35.9  24.1  89.8  78.\n",
      "  32.9  77.5  83.4  54.7  56.8  77.8  59.6  55.9  18.5  79.2  73.3  56.3\n",
      "  80.1  65.9  41.8  43.6  56.6  64.9  45.   69.2  80.9  56.1  72.3  57.2\n",
      "  43.4  66.9  76.5  59.1  69.5  79.   80.5  52.1  45.7  51.3  79.3  29.6\n",
      "  71.8  19.3  21.8  62.2  37.5  23.6  67.4  84.9  81.6  54.2  45.2  53.4\n",
      "  65.6  77.1  48.   74.   72.6  61.3  73.9  45.9  38.4  72.4  24.   37.2\n",
      "  64.3  62.1  47.5  48.8  38.8  34.4  48.4  36.   34.3  68.7  14.2  55.4\n",
      "  49.5  44.7  34.5  69.3  39.2  32.   36.7  51.7  18.8  29.9  33.2  41.2\n",
      "  31.7  35.4  76.2  50.4  43.7  44.5  27.6  33.   23.9  47.2  48.7  86.5\n",
      "  19.5  35.2  43.3  57.9  30.4  35.6  74.1  42.1  88.6  58.8  34.1  27.4\n",
      "  29.5  21.   66.7  17.4  54.9  36.6  79.7  62.4  19.4  34.7  36.1  63.9\n",
      "  69.8  81.7  31.1  11.8  12.6  32.6  42.2  23.8  25.4  22.2  28.3  34.\n",
      "  17.1  55.   53.6  39.7  24.4  65.7  59.3  26.2  57.   49.8  89.2  61.7\n",
      "  60.6  45.1  44.8  35.   20.4  22.5  38.3  46.   82.9  50.1  42.3  59.5\n",
      "  63.8  40.4  81.4  53.2  26.1  70.7  87.7  72.7  96.2  76.8  73.5  40.9\n",
      "  42.6  43.8  71.4  16.2  30.1  11.1  76.   13.8  10.8  28.   56.7  44.1\n",
      "  69.7  31.2  14.1  55.1  30.2  22.1  15.2  30.3  23.   50.   52.9  15.5\n",
      "  18.9  13.7  17.8  20.7  17.   21.7  10.2  16.3  25.1  43.5  75.1  14.4\n",
      "  11.3  28.2  19.   15.1  66.2  71.7  34.9  28.7  46.9  54.6  63.4  55.3\n",
      "  58.3  70.4  67.8  12.9  53.3  64.6  69.6  54.5  29.1  93.2  55.6  33.1\n",
      "  61.6  55.2  26.9  91.9  67.3  54.8  29.8  57.1  87.6  85.   74.4  54.4\n",
      "  92.6  47.   52.   91.   21.6  60.7  25.9  83.2  55.8   6.2  99.8  62.3\n",
      "  97.4  56.9  84.5  33.9  81.5  65.3  79.4  16.7  68.8  64.2  42.9  26.6\n",
      "  12.2  18.   56.5  65.2  69.1  80.6  86.3  91.2  66.6  48.3  65.8  50.8\n",
      "  77.4  21.5  17.7  16.4  54.   96.7  68.9   0.   14.6  92.2  78.1  83.3\n",
      "  29.   40.5  78.8  19.9  79.9  80.2  16.6  93.1  28.9  49.7  85.3  27.2\n",
      "  89.5   7.6  66.5  74.7  24.5  87.9  90.2  87.1  75.7  71.9  78.2  67.1\n",
      "  83.9  70.3   9.1  69.4  46.8  20.5  67.9  71.5  53.5  59.4  73.4  23.2\n",
      "  72.2  89.4  78.4  83.   97.   81.1  75.8  11.7  62.6  53.8  10.3  89.9\n",
      "  46.3  10.7  81.8  55.7  95.6  78.7  86.7  84.7  92.8  60.8  94.5  53.7\n",
      "  59.2  67.   58.5  59.   14.7  77.   88.2  16.   84.8  98.8   7.8  70.2\n",
      "  78.5  68.5  66.3  67.7  13.4  89.1  82.8  68.3  80.4  79.8  94.1  88.7\n",
      "  64.   87.3  85.8  89.7  92.5  59.7  79.1  73.8  93.   90.   70.5  27.5\n",
      "  63.6  78.6  17.3  14.5 100.   21.2  86.2  87.   11.   52.5  79.5  86.9\n",
      "  18.7  96.4   9.6  22.9  81.3  82.5  90.3  73.6  62.   94.2  20.6  87.5\n",
      "  98.   74.8  63.   90.5   nan  89.6  63.1  73.1  72.   86.6  76.4  80.7\n",
      "  72.5  85.6  76.6  91.6  66.4  78.3  77.7  85.9  85.2   7.5  61.1  97.3\n",
      "  83.8  81.2  82.4  87.4  82.1  60.1  97.6  75.4  18.2  77.3   8.8  68.1\n",
      "  94.9  88.8  85.5  88.4  89.3   6.7  75.3  98.9  72.1  81.9  74.9  95.4\n",
      "  90.9  67.5   9.2  98.6  63.2  86.4  91.4  96.   94.6  74.6  92.9  80.3\n",
      "  87.8  89.   12.8   2.9]\n",
      "pell_percentile: [ 98.  39.  91.  32. 100.   7.  93.  56.   3.  16.  89.  97.  59.  74.\n",
      "  68.  85.  88.  81.  70.  37.  62.  86.  77.  35.  46.  72.  95.  61.\n",
      "  64.  78.  82.  96.  92.   6.  76.  84.  40.  87.  13.  11.   4.  29.\n",
      "  41.  58.  42.  17.  22.  31.  21.  30.  47.  65.  19.  27.  33.  12.\n",
      "  71.   5.  24.  57.  69.  54.  49.  26.  10.  90.  28.  38.  55.  94.\n",
      "  45.  43.  80.  73.  25.  52.  18.   1.  66.  67.  48.   2.   9.  15.\n",
      "  79.  23.   8.  14.   0.  34.  36.  60.  83.  75.  20.  51.  44.  50.\n",
      "  63.  53.  99.  nan]\n",
      "retain_value: [ 63.1  80.2  37.5  81.   62.2  87.   42.7  63.2  89.5  80.4  51.6  41.\n",
      "  19.4  54.1  52.1  50.   55.9  56.   63.7  53.1  62.   42.3  71.1  51.8\n",
      "  52.4  57.5  59.7  52.5  57.8  57.   38.1  54.8  77.3  73.7  52.6  70.8\n",
      "  61.4  78.8  56.7  83.3  48.8  41.2  86.7  42.   58.5  59.4  67.9  75.6\n",
      "  64.3  61.2  32.9  49.8  73.9  72.4  58.1  70.6  76.9  71.6  66.7  43.3\n",
      "  40.   71.8  72.7  65.2  44.7  84.4  62.5  81.5  84.6  49.3   0.   82.8\n",
      "  59.5  58.8  87.5  77.8  55.3  56.3  52.9  80.   26.4  60.3  46.1  60.7\n",
      "  80.6  72.9  73.4  69.4  19.2  57.6  68.1  70.7  17.9  62.6  69.7  39.5\n",
      "  69.8  82.1  56.2  54.9  73.1  42.4  59.1  67.3  59.   66.1  45.2  48.7\n",
      "  47.7  82.3  57.2  87.8  82.4  50.8  76.3  53.8  54.7  54.3  55.7  51.5\n",
      "  60.1  50.6  57.4  71.   72.   63.3  64.1  68.3  74.3  71.3  53.7  92.9\n",
      "  85.   70.4  74.   76.8  81.9  96.6  84.8  92.5  75.   74.4  87.2  88.8\n",
      "  90.   86.6  79.3  83.2  88.5  77.5  78.2  82.5  96.4  91.8  96.3  89.\n",
      "  94.2  91.9  27.4  79.4  65.6  76.2  73.8  73.2  90.7 100.   96.2  61.1\n",
      "  63.6  67.1  77.   71.2  72.3  73.3  79.   75.1  85.7  78.9  80.5  93.5\n",
      "  64.8  82.6  75.3  68.7  73.   69.1  99.5  63.   57.3  56.9  77.6  69.2\n",
      "  74.7  62.8  87.9  84.2  59.3  47.5  69.   74.8  59.9  75.7  80.8  69.5\n",
      "  71.9  54.5  91.4  83.9  83.6  66.5  65.8  50.3  81.2  67.   65.9  74.9\n",
      "  79.2  56.4  60.   76.6  93.   76.7  77.2  80.9  72.5  64.5  91.7  90.8\n",
      "  89.3  97.5  68.5  55.2  66.3  88.4  41.4  67.5  68.8  73.5  66.9  85.1\n",
      "  67.7  90.2  65.4  86.5  77.1  60.4  75.8  82.2  61.7  95.   93.2  67.6\n",
      "  72.2  54.4  70.1  70.2  84.   76.1  78.4  93.8  96.   64.6  86.9  14.3\n",
      "  65.   67.8  66.2  61.9  58.3  72.6  82.9  74.6  43.8  61.8  54.2  63.9\n",
      "  75.2  71.4  57.1  96.1  65.7  48.3  40.6  94.1  85.9  53.2  42.1  86.8\n",
      "  57.9  65.3  58.2  85.4  68.4  92.6  34.8  88.3  93.9  78.1  51.7  61.6\n",
      "  60.2  62.4  76.4  93.3  48.4  85.2  25.   90.9  95.1  98.7  59.2  59.8\n",
      "  55.1  88.2  68.9  92.3  78.6  87.1  26.1  50.9  76.5  67.2  70.5  79.7\n",
      "  83.5  55.6  91.   96.5  21.7  50.2  71.7  91.3  81.7  63.8  77.9  83.4\n",
      "  58.7  47.2  49.2  70.   44.3  67.4  65.1  55.   45.5  51.3  84.7  45.\n",
      "  94.4  64.7  58.6  95.5  61.5  49.7  31.6  82.   80.1  53.9  80.7  59.6\n",
      "  88.1  47.1  64.   71.5  61.3  60.5  66.   88.   76.   50.7  53.6  99.3\n",
      "  49.6  38.2  44.5  45.4  51.2  66.6  66.4  29.8  33.3  21.8  79.8  93.1\n",
      "  87.6  81.3  86.   36.4  81.6  62.9  39.1  69.3  56.5  42.5  29.6  75.9\n",
      "  35.4  97.7  61.   75.4  46.2  79.1  75.5  38.7  49.5  63.4  94.5  84.1\n",
      "  91.1  92.2  72.8  49.   63.5  60.9  89.8  60.8  25.9  98.6  91.2  69.9\n",
      "  89.4  74.1  86.4  52.   85.3  82.7  52.8  81.8  47.   70.3  51.   51.1\n",
      "  46.   85.8  36.2  83.   37.6  30.2  62.3  52.3  16.7  55.4  44.2  32.4\n",
      "  79.9  47.6  91.5  55.8  65.5  58.4  74.5  48.1  81.1  53.3  44.8  48.5\n",
      "  62.1  52.2  62.7  36.7  87.3  56.1  46.6  51.4  43.5  53.5  45.6  43.2\n",
      "  48.9  90.5  91.6  74.2  45.7  47.9  77.7  97.   35.7  94.7  68.2  72.1\n",
      "  97.6  94.9  94.8  80.3  92.8  81.4  88.6  97.1  95.2  78.7  88.9  97.9\n",
      "  51.9  64.2  86.2  93.7  84.3  98.   95.9  87.4  56.6  41.9  56.8  53.4\n",
      "  96.9  47.8  40.8  84.5  64.4  84.9  30.   92.1  58.9  73.6  42.6  85.5\n",
      "  69.6  78.3  54.6  85.6  53.   78.5  89.1  43.1  52.7  29.4  43.6  64.9\n",
      "  46.9  54.   78.   44.4  31.2  68.6  50.4  42.9  70.9  58.   79.5  83.1\n",
      "  37.7  55.5  41.8  46.7  37.   57.7  35.8  97.3  95.6  96.8  94.   97.4\n",
      "  95.7  39.4  95.8  90.4  40.2  25.3  79.6  83.7  41.7  50.1  90.1  83.8\n",
      "  90.3  87.7  46.3  88.7  97.8  48.2  49.1  97.2  42.2  89.9  66.8  35.2\n",
      "  44.9  38.9  47.4  48.   89.6  93.4  92.4  50.5  45.8  15.4  20.   31.9\n",
      "  86.3  35.6  39.7  33.1  43.9  45.1  45.3  49.4  32.2   3.2  26.3  60.6\n",
      "  94.3  68.   44.6  36.5  38.5  31.   41.1  48.6  49.9  35.1  24.7  40.3\n",
      "  41.5  46.8  43.7  44.   98.2  93.6  31.5  23.1  77.4  96.7  39.8  90.6\n",
      "  34.7  34.4  30.5  26.7  40.9  35.   26.2  28.9  44.1  27.3  46.4  45.9\n",
      "  22.2  38.6  28.6  38.4  33.8  29.3  37.2  40.7  37.1  31.4  27.8  40.4\n",
      "  32. ]\n",
      "retain_percentile: [ 17.  70.   2.  72.  15.  87.   5.  92.  65.  23.   1.  33.  25.   6.\n",
      "  42.  77.  29.  38.  18.  40.  24.  26.  49.  14.  27.   8.  47.  10.\n",
      "  56.  28.  67.  60.  46.  88.   4.  80.  54.  58.  30.  51.  22.  50.\n",
      "  39.   3.  62.  32.  82.  73.  16.   0.  59.  57.  89.  76.  44.  43.\n",
      "  34.  64.  84.  66.  45.  36.  75.   7.  37.  35.  12.  71.  83.  20.\n",
      "  53.  41.  61.  19.  48.  93.  96.  91.  81.  55.  97.  52.  86.  68.\n",
      "  79.  99.  95.  98.  94.  85.  78.  63.  74.  11.  90.  69.  21.  13.\n",
      "  31.   9. 100.]\n",
      "ft_fac_value: [ 82.8  92.4  67.2  65.5  67.   69.5  38.3  60.1  88.7  71.7  26.7  61.8\n",
      "  14.6  41.6  38.1  42.4  46.3  59.8  33.4  48.2  30.8  36.6  37.   65.2\n",
      "  48.6  32.1  30.   45.9  39.2  50.8  54.8  75.   77.7  58.2  57.6  50.3\n",
      "  68.9  36.   76.9  36.8  80.   66.7  53.8  63.7  81.   41.4  29.9  68.6\n",
      "  56.2  35.   87.9  81.1  64.4  37.4 100.   34.6  47.4  69.4  47.5  37.6\n",
      "  21.2  22.2  24.   42.1  64.3  14.8  87.6  31.1  76.4  56.5  21.4   6.7\n",
      "  24.9  25.7  70.2  31.4  11.   49.4  28.   29.1  11.4  20.7  61.2  32.2\n",
      "  21.    5.6  27.3  39.4  35.4  90.5   2.3  30.2  26.3  20.5   1.8  52.6\n",
      "  60.9  63.6  70.7  86.2  49.2  73.9  61.6  72.7  51.7  73.7  40.3  45.2\n",
      "  45.8  32.   43.8  69.6  67.8  33.1  75.6  46.4  71.4  78.3  63.4  67.3\n",
      "  39.1  34.1  44.   30.4  58.   49.5  65.6  52.2  54.3  18.9  36.2  26.1\n",
      "  18.6  40.4  38.9  31.6  43.1  53.7  12.   54.7  40.5  26.4  15.6  97.6\n",
      "  40.8  68.5  79.4  65.1  56.3  50.5  48.8  52.8  38.8  51.8  46.2  50.\n",
      "  46.   48.9  74.7  81.5  77.4  77.2  81.4  81.7  20.3  55.9  66.3  29.4\n",
      "  25.4  55.   34.5  36.9  41.   23.7  33.2  20.4  43.9  92.   14.7  30.7\n",
      "   1.3  28.9  42.3  34.4  20.   31.5  35.8  24.3   7.1  28.5  35.3  37.5\n",
      "  31.7  24.4  16.1  23.8  50.7  33.9  38.   26.2  32.4  24.6  31.3  25.2\n",
      "  30.5  89.6  61.7  32.7  39.3  35.1  46.7  23.9  54.1  33.3  18.8  30.6\n",
      "  28.3  42.2  26.8  38.2  18.7  50.4  33.7  11.6  54.2  24.8  17.8  34.9\n",
      "  35.2  41.8  27.8  32.9  28.1  17.7  29.   24.2  44.7   7.3  22.1  25.3\n",
      "  35.7  89.4  68.8  90.1  55.1  44.4  32.5  46.1  82.7  15.1  25.8  42.9\n",
      "  43.4  49.7  40.2  57.1  45.7  35.6   6.3  13.2  46.6  60.2  22.7  23.5\n",
      "  72.6  86.   37.9  21.6  19.7  37.8  16.7  30.9  40.6  67.1  36.1  96.9\n",
      "  15.4  16.9  67.5  60.4  32.3  23.2  26.   35.9  26.5  43.6  63.2  61.\n",
      "  26.9  29.8  22.   86.7   1.1  83.5  52.9  15.9  68.4  39.5  68.3  13.5\n",
      "  11.2  25.   96.6   9.8  72.2  45.    3.1   8.3  57.7  66.   22.6  23.3\n",
      "  27.4  47.7  46.8  54.4  72.5  20.6  21.7  91.8  29.3  41.3  99.6  21.3\n",
      "  46.5  20.1  27.1  27.2  25.6  12.2  18.5  19.   39.6  74.1  87.8  34.7\n",
      "  85.4  34.8  65.4  95.7  55.6  45.1  99.5  46.9  60.7  31.8  28.7  41.9\n",
      "  71.   38.5  66.2  67.7  57.   80.2  70.6  61.1  53.3  30.3  56.   64.\n",
      "  45.5  50.6  71.8  86.1  19.6  10.8  97.9   3.2  61.5  70.   84.9  62.9\n",
      "  37.3  17.2  55.5  34.3  63.8  75.2  60.8  47.9  33.8   8.1  56.9  70.1\n",
      "  47.6  64.1  88.   62.5  42.   52.1  52.3  73.   58.8  70.3  61.4  81.9\n",
      "  81.8  85.7  76.5  87.1  73.6  87.   53.2  38.6  12.9  67.4  77.   74.6\n",
      "  51.4  28.4  79.7  78.2  37.1  47.1  35.5  79.1  80.3  36.7  36.5  69.\n",
      "  60.6  48.4  58.6  47.8  44.9  19.3  77.9  63.1  48.3  43.5  23.4  58.5\n",
      "  59.9  27.5  71.2  84.2  33.   18.1  27.7  48.1  32.6  12.5  62.   70.9\n",
      "  75.7  13.7  41.1  28.6  14.4  79.9  21.5  83.   12.1  29.2  58.3  66.9\n",
      "  40.7  29.5  49.3  38.7  22.3  23.1  44.1  34.   52.4  42.6  59.5  91.7\n",
      "  87.3  69.3  90.3  41.5  89.1  82.   65.8   0.   94.4  64.7  75.8  39.7\n",
      "  22.5  70.5  14.   41.2  50.2  69.1  48.   86.6   2.5  79.2  76.3  93.8\n",
      "  88.2  77.5  55.3  90.2  16.2  94.7  63.5  57.4  60.   65.   39.9  84.\n",
      "  40.9  82.3  84.5  22.8  88.1  72.9  74.8  93.2  51.3  74.3  59.2  56.6\n",
      "  12.6  73.3  19.8  77.8  10.   51.6  31.2  85.9  59.1  50.9  75.3  61.9\n",
      "  27.   88.4  43.   27.9  92.5  55.4  73.8  80.4  83.7  59.7  74.5  45.4\n",
      "  76.7  73.2  74.4  10.3  54.9  44.3  83.6  65.9   nan  47.2  89.   27.6\n",
      "  80.7  85.5  79.5  69.2  51.5  78.1  62.6  80.5  47.   70.8  89.3  84.7\n",
      "  82.6  16.   40.   17.9  52.7  28.8  42.5  40.1  19.4  24.1  49.9  19.2\n",
      "  17.6   8.2  29.7  14.2   5.9  75.4   6.5  32.8  62.2  91.1  54.5  21.8\n",
      "   7.4  22.9   7.   57.2  33.5  89.9  86.5  23.6  82.2  98.8  89.8  64.6\n",
      "  93.9  17.3  16.6  80.6  82.5  30.1  49.6  78.4  57.9  34.2  71.3  73.1\n",
      "  67.6   4.   16.4  44.6  98.6  10.2  87.5  25.9  13.4  10.6  37.7  84.3\n",
      "  31.   22.4  42.7  18.3  78.7  78.   17.5  42.8   3.7  49.1  39.8  53.4\n",
      "  64.9  57.3  72.3  62.8  85.1  86.4  92.2  82.4  75.5  76.8  28.2  72.\n",
      "   8.4  84.6  29.6  25.1  15.8  88.9  50.1  53.1  83.2  63.9  10.9  48.7\n",
      "  69.7  43.3  64.2  83.4  62.4  75.9  56.4  63.3  19.5  49.8  14.3  83.3\n",
      "  92.8  55.8  64.5  78.9   7.7   8.5  12.3  92.3   9.2  15.7  44.2  12.7\n",
      "  14.9  84.8  48.5  60.5  38.4  36.4  51.   18.2   3.3  51.2  87.2  43.2\n",
      "  96.5  10.1  80.8  36.3  59.3  55.7  88.6  10.7  45.6  31.9  21.9  19.9\n",
      "   4.5  73.5  66.4  91.   94.1  18.4  73.4  57.5  58.4  41.7  71.9  53.5\n",
      "  71.1  63.   66.1  85.8  61.3  90.9  79.3  58.1  57.8  12.4  93.5  94.3\n",
      "  97.2  54.   93.1  24.7  33.6  79.6  72.1  51.1  24.5  60.3  70.4  97.8\n",
      "  98.1  58.9  25.5   8.   95.2  21.1  52.   59.6  78.6  20.8  13.3  76.\n",
      "  11.1  71.6  66.8  79.   44.5  99.4  53.9  82.1  64.8  76.6  77.3  26.6\n",
      "  96.4  71.5  51.9  49.   84.4  65.7   1.9  80.1  81.2  90.   17.   20.9\n",
      "  55.2  56.7  77.6  91.2   9.1  84.1  11.5  93.6  74.2  86.8  65.3  98.7\n",
      "  18.   83.1  52.5  16.3  37.2  93.3  78.5  53.   43.7  99.2  58.7   4.7\n",
      "  68.1  96.2  75.1  17.4  99.3  53.6  68.2  91.5  90.7  69.9  76.2  92.6\n",
      "  96.3  23.   95.4  15.5  59.4  80.9  78.8  93.   14.5  88.5  59.    4.2\n",
      "  45.3  54.6  77.1  72.4  44.8   6.2  69.8  97.1  20.2   9.7   5.3  13.\n",
      "  19.1   2.    4.9  17.1   8.6   3.   11.8   6.9   7.5  62.7  15.   14.1\n",
      "  15.2   3.9   9.4  10.4   9.6  13.6   4.4   8.7   4.6  11.9  15.3   8.8\n",
      "   3.4   8.9   9.5   6.1   5.8  39.    5.2   5.4   2.4  81.6  11.7  67.9\n",
      "   4.1   7.2  13.1  13.9  16.5  10.5   5.    7.9   2.2  95. ]\n",
      "ft_fac_percentile: [89. 98. 71. 56. 58. 64. 66. 44. 96. 76. 31. 63. 40. 65. 36. 79. 93. 52.\n",
      " 82. 75. 28. 62. 55. 83. 48. 42. 41. 68. 30. 90. 81. 85. 60. 80. 95. 84.\n",
      " 70. 61. 25. 94. 12. 22. 23. 29. 57. 17. 54. 46. 77. 92. 15.  9. 73. 47.\n",
      " 27. 19. 35. 39. 13. 99. 14.  6. 33. 43.  0.  8. 87. 45. 74. 86. 72. 32.\n",
      " 51. 97. 67. 37.  3.  5. 38. 26. 20. 16. 11. 59. 53. 49. 24. 91. 50.  7.\n",
      " 21. 34. 78. 69. 18. 10. 88.  1.  2.  4. nan]\n",
      "vsa_year: [2010. 2011.   nan 2008. 2009.]\n",
      "vsa_grad_after4_first: [14.7 22.3  nan 12.8  4.1 35.5  8.5 17.2  7.7 30.7 35.7 18.5 11.1 27.\n",
      " 17.6 23.1  1.2 19.2 20.2  6.  16.9 14.  12.7  8.1 14.2  9.1 46.9  8.7\n",
      " 28.2 14.3  6.5 31.2 14.1 21.1 39.7 36.5 10.3  3.1 27.5 13.6 67.7 32.1\n",
      " 14.8 13.2 58.3 34.5 16.5 19.1 50.1 25.5 22.8 18.3 52.3 23.  35.9 64.1\n",
      " 27.3 47.  25.9 28.7 34.6  7.2 13.9  4.5  6.2 36.7 43.7 35.3 20.8 32.\n",
      " 22.7 24.1 16.   4.7 32.4 21.2  9.9 22.9 26.2 41.1 12.4  5.1 10.  10.5\n",
      " 15.9 12.5 18.7  8.3 23.3 62.5 19.6 46.3 37.  52.  28.4 26.3 47.7 13.\n",
      "  9.5 26.7 20.5 47.2 19.7 23.5 17.  20.  33.9 29.  22.1 43.1 25.4 24.8\n",
      " 28.8 23.2 31.9 12.3 18.1 20.9 20.6 20.7 11.5 29.7  7.9 13.3 13.7 41.5\n",
      " 51.4 67.9 45.8 40.  73.7 17.7  0.5  9.8 66.5 53.8 40.4 38.  29.2 15.8\n",
      " 75.5 27.2 28.9  0.  40.7 45.  15.4 15.7 32.6 20.1 11.9 36.2  9.7 48.5\n",
      " 45.2 22.4 20.3 11.2 13.8  9.4 34.9 41.3 31.5 15.3 24.6 36.4 30.8 33.\n",
      " 32.5 62.7 61.4 43.  36.3 34.3 14.6 37.7 53.4 59.8  4.2 18.2 45.1 24.\n",
      " 21.7 16.7 18.  19.4 35.6 16.2 19.3  2.4 14.9 13.1  7.5 21.6 25.1 15.\n",
      " 46.2 40.3  7.3 15.2  3.6 36.9  5.2 20.4  5.6  5.7 59.2 37.9 21.4 36.\n",
      " 21.3 32.7 14.4  7.8 19.  51.2 15.5 21.9 37.4 56.6 10.2]\n",
      "vsa_grad_elsewhere_after4_first: [ 2.   2.9  nan  4.7  1.3  3.1  2.6  3.2  3.8  3.   4.1  1.4  3.4  0.7\n",
      "  1.5  2.7  2.2  1.6  2.4  0.   3.9  4.   1.9  5.2  5.8  3.6  7.8  5.1\n",
      "  4.4  5.5  7.2  5.6  9.1  5.3  7.7  4.2  3.5  1.8  4.3  3.7  4.5  8.2\n",
      "  6.8  4.6  7.   3.3  5.   1.1  8.5  2.3  7.9  6.6  0.9  7.1  5.4  1.2\n",
      "  6.5  4.9  4.8  5.7  6.7  2.5  5.9  8.8  8.6  6.2 10.1  7.6 10.   2.8\n",
      "  7.5 11.7  9.2  6.4  0.8  7.4  6.3]\n",
      "vsa_enroll_after4_first: [36.5 34.2  nan 42.8 67.8 39.7 42.1 37.4 34.  29.5 34.9 29.8 20.5 50.9\n",
      " 43.3 40.9 69.3 54.9 53.6 45.9 52.4 54.  62.4 58.7 55.  57.9 30.5 45.2\n",
      " 43.6 51.  62.9 32.7 37.7 36.4 34.7 33.3 25.1 24.8 47.2 18.4 29.2 41.4\n",
      " 24.4 36.7 47.9 27.9 33.2 40.1 38.3 48.3 36.3 52.3 22.3 25.2 33.4 29.7\n",
      " 31.1 27.4 36.1 23.5 35.7 23.1 39.5 37.2 28.  44.1 32.  35.6 33.9 29.9\n",
      " 33.8 40.4 32.8 37.8 32.6 41.5 16.4 37.6 41.8 31.4 28.1 43.9 32.4 31.5\n",
      " 22.8 24.5 32.9 23.4 30.6 39.9 46.1 41.2 30.7 37.1 27.1 38.5 32.3 34.5\n",
      " 30.1 31.  39.  49.9 29.4 38.4 35.8 38.8 42.6 35.4 39.3 28.9 44.6 48.9\n",
      " 21.4 50.1 14.5 11.8 23.7 16.6 19.9 50.  16.  35.1 17.3 18.  35.5 36.8\n",
      " 36.9 43.7 39.8 32.1 67.1 27.8 33.5 44.3 25.   7.2 30.8 46.2 15.6 22.2\n",
      " 24.  35.  41.6 36.6 26.1 28.6 28.8 28.3 24.6 25.9 21.6 21.3 29.3 39.6\n",
      " 16.8 15.8 78.4 31.7 26.7 17.5 25.3 25.4 34.3 26.2  2.3 28.5 45.7 37.\n",
      " 35.3 41.7 38.1 33.7 56.4 47.4 17.  23.9 31.8 37.3 38.  38.7 40.8 42.2\n",
      " 45.3 41.1 47.1 43.1 16.9 44.4 60.1]\n",
      "vsa_enroll_elsewhere_after4_first: [16.1 19.2  nan 18.3 13.2 12.1 16.4 15.2  9.8 19.4 10.6 11.7 10.7 20.5\n",
      " 17.  14.5 15.1 25.  15.4 14.7 18.8 19.5  0.  26.  21.2 18.9 22.1 24.2\n",
      " 13.4 13.9 22.9 23.  15.7  7.4 16.2 17.8 21.1  7.3 12.4 20.8 13.5 11.\n",
      " 15.9 20.9 22.6 16.3  6.2 16.9  5.4  7.5 17.6 21.6 18.4 17.5 18.2 21.4\n",
      " 19.6 24.9 23.1 11.5 12.8 19.8 15.  13.1 13.8 14.8 22.3 18.1 15.3 16.8\n",
      " 17.1 12.2  8.4 11.8 15.5 14.6 12.7 13.7 15.8 17.9 20.2 19.3  9.  21.8\n",
      " 18.6  9.7 14.4 25.1 19.  17.2 16.7 14.9 16.  19.7 18.7 17.3  6.8  9.9\n",
      " 12.6  5.5  8.9 20.1 14.1 15.6  2.6 19.1  9.6 22.8 13.  17.7 26.6 16.6\n",
      " 24.7  8.2  8.3 10.8 14.2 16.5  4.8 12.3 13.6 10.5 24.3 27.2 22.5 12.9\n",
      " 24.5 13.3 23.2  2.3 29.7 21.   8.8  8.  27.3 20.3 27.7 20.7 32.5 18.\n",
      " 20.   6.6 17.4 11.4 12.  23.7 27.6 24.1]\n",
      "vsa_grad_after6_first: [33.  42.6  nan 43.  60.6 66.4 32.  37.8 24.8 51.5 58.8 36.2 29.3 74.6\n",
      " 43.3 30.9 37.1 56.4 63.1 19.9 50.9 50.5 54.3 38.4 36.8 40.7 60.9 34.9\n",
      " 64.8 47.9 34.5 57.  41.1 45.1 67.7 63.7 25.7 15.8 47.4 27.6 47.2 82.4\n",
      " 52.5 43.8 40.4 70.  63.  42.  72.9 50.4 47.8 44.8 48.3 79.  74.  81.6\n",
      " 56.2 67.  45.7 52.2 57.5 25.6 31.8 48.1 21.2 25.8 17.1 71.  68.8 66.7\n",
      " 37.9 60.7 54.6 39.1 42.8 37.6 21.4 57.4 48.4 28.  49.  26.7 58.7 45.9\n",
      " 22.  27.9 28.7 33.4 39.3 27.3 38.5 57.8 81.5 33.5 73.2 53.4 68.4 45.6\n",
      " 61.1 76.  64.9 41.4 30.1 49.9 51.1 50.6 70.2 47.3 59.8 58.  46.3 31.4\n",
      " 69.3 65.3 50.2 69.5 51.4 47.  54.5 26.  46.6 40.9 38.7 48.  39.6 34.1\n",
      " 47.6 39.  49.1 55.4 61.9 46.9 62.2 76.8 62.7 62.9 86.2 34.7 16.3 42.5\n",
      " 78.4 67.6 55.2 65.5 52.9 44.5 34.  55.  88.7 55.1  0.  72.4 66.9 52.\n",
      " 25.2 53.7 52.6 60.4 55.5 30.  49.8 80.1 77.7 64.5 18.6 44.  36.6 35.\n",
      " 34.8 25.5 62.5 62.4 53.3 26.5 58.2 44.2 53.6 53.5 53.2 60.2 85.1 78.6\n",
      " 59.4 60.3 43.1 59.3 66.  74.7 40.  15.  69.6 44.7 38.8 48.6 31.7 13.9\n",
      " 35.1 23.7 49.4 44.4 55.8 79.2 38.3 59.7 34.3 13.5 37.2 29.4 41.  14.\n",
      " 15.6 72.1 56.5 79.9 46.2 68.1 68.7 35.8 46.1 55.9 62.  70.9 27.1 52.7\n",
      " 80.9 51.2 59.9 68.3 23.  38.2]\n",
      "vsa_grad_elsewhere_after6_first: [ 5.3 10.5  nan 14.5  8.   9.6  9.5  8.1  8.5 11.5  9.2  6.8  6.4  5.\n",
      "  5.2 10.6  4.   7.8  5.8  4.7  6.3  6.   8.3  8.6  3.9 11.2 10.3 10.9\n",
      "  5.9 15.  13.6 15.5 10.1 15.6  6.9 15.3 11.9 12.   7.  13.1 11.8  9.3\n",
      " 10.2 16.3 10.4 10.7 11.1 18.4 12.1  7.9  5.4 14.8 12.9 14.6 13.2 17.8\n",
      "  9.7 17.2 11.6 13.3 11.3  9.9  7.4 13.5  9.   4.9 12.7  7.5 10.   6.7\n",
      " 16.5  2.2 14.  16.7  0.  13.4  6.5 14.3 19.1  4.6 12.2 11.4 12.6 15.2\n",
      " 15.7  9.8 12.5 14.4 13.7 14.9  8.7 16.6 10.8  4.4  5.6 16.9  2.9  4.2\n",
      " 21.6 17.9 19.4  9.4  9.1  5.7  8.8 12.8 15.1 13.   6.1 21.9 25.  15.8\n",
      "  7.1 12.4 17.4 16.8 20.2  4.5 16.  11.  17.5 15.9 22.5 13.8]\n",
      "vsa_enroll_after6_first: [12.5  7.9  nan 10.2  9.9  5.  11.3 11.1 10.3  4.4  4.7  7.4 10.9  2.1\n",
      " 12.7 18.1 23.4 12.8  6.  19.  12.1 15.  20.3 14.5 14.1  5.5 12.   4.3\n",
      " 11.5 20.4  3.   8.8  4.2  4.1  8.5 15.4  5.9  7.7  1.5  3.6  7.   2.6\n",
      "  2.4  6.6  8.9  6.3 11.9  4.8  1.   1.7  6.8  6.2 10.1 13.3  3.1  1.9\n",
      "  6.7  4.5  5.6 11.7  7.2  5.3  8.2  7.5  4.9 10.  13.   9.7 11.2  1.6\n",
      "  3.7  2.9  3.9  9.4  4.6  3.5  5.2  3.4  6.9  9.3  7.1  6.1  0.8  1.8\n",
      " 13.5  9.8  1.3  4.  10.8  1.4  5.1  5.8 17.2 12.6  0.9  3.3  5.7 11.8\n",
      "  8.3  6.5  9.2  2.   2.8  5.4 12.2  2.3  2.7  2.5  1.2 12.3  3.8 11.4\n",
      "  7.3 15.5  8.1  9.6 25.6 17.4 18.3  0.7  3.2  7.6  9.5 16.5]\n",
      "vsa_enroll_elsewhere_after6_first: [14.6 13.1  nan 11.7  8.   7.6 13.8 11.3  7.2 11.5  7.5  8.8 11.4  5.9\n",
      " 15.1 11.6 13.4 10.5  9.2 19.6 11.9 14.2 11.1 18.8 15.7 16.4  0.  17.9\n",
      " 13.7 15.5 12.2 10.7  6.9 12.8 13.   9.3  3.1  8.1  9.   6.2  7.9  9.6\n",
      "  5.5  9.9  8.6  9.7  2.8 10.4  5.   3.8  9.8  6.1 12.6  9.4 12.4 12.1\n",
      " 12.5 14.7  5.8  4.2  8.7  7.8 10.  15.9 10.1  8.9  8.4 18.3 10.6 11.2\n",
      "  8.2  6.6 10.8 11.   4.6 13.3  3.9 21.3  6.8  8.3  5.1  9.1 14.5 16.9\n",
      "  5.3  9.5 10.2  7.  10.9  6.5  4.7  6.3  5.7  4.   6.4  5.4  3.  16.7\n",
      "  4.9 12.3  1.5 12.7 21.5  6.7 14.8 11.8  7.4 15.   4.8 10.3  7.1  2.1\n",
      "  2.9 16.1 16.   4.3 23.8 14.3 15.6 14.9 18.1 16.5 17.6 16.3 15.8 12.\n",
      "  3.4 18.9 33.7]\n",
      "vsa_grad_after4_transfer: [15.7  nan  0.  45.8 64.2 46.4 35.9 24.7 62.5 50.9 45.  10.8 78.7 63.8\n",
      " 70.9 61.5 70.4 65.1 57.2 68.1 71.6 73.4 48.8 74.9 60.9 74.1 73.3 58.9\n",
      " 71.9 51.1 58.7 54.5 43.6 21.  51.2 43.2 49.6 74.4 52.5 46.5 45.1 75.3\n",
      " 61.  72.9 78.6 75.9 53.  63.5 54.3 57.4 78.1 73.5 82.5 64.8 62.9 69.1\n",
      " 52.1 60.6 28.8 39.1 50.1 20.9 25.1 26.  59.7 62.3 59.4 48.7 47.5 54.\n",
      " 37.8 49.5 44.4 50.2 38.6 37.3 68.3 29.6 54.7 41.4 40.7 29.2 23.2 37.7\n",
      " 29.7 35.1 31.1 72.1 58.5 55.3 67.6 31.  65.6 54.8 66.9 43.5 46.3 76.1\n",
      " 66.7 47.7 33.  53.5 56.8 50.3 45.6 50.8 44.3 56.7 46.8 34.9 56.5 47.8\n",
      " 53.4 72.2 55.7 55.1 34.8 38.  42.3 47.  52.  45.9 39.3 42.7 55.4 70.1\n",
      " 58.  65.7 46.6 75.6 58.4 74.  68.8 57.9 44.9 27.6 83.  55.9 68.9 67.9\n",
      " 31.5 44.7 33.2 62.2 42.2 48.4 38.9 73.9 64.5 59.1 48.  35.  43.1 64.7\n",
      " 60.4 42.  59.2 52.9 52.4 57.5 88.  69.3 61.7 64.9 40.6 46.7 58.8 78.5\n",
      " 20.  66.1 51.6 36.1 38.8 60.2 36.7 40.8 45.3 35.3 76.5 45.7 47.9 51.7\n",
      " 15.1 58.2 50.  50.6 17.8 59.8 28.3 72.3 81.3 75.7 41.1 51.9 52.3 50.7\n",
      " 51.4 52.2 58.6 37.2 46.1 56.1 50.4 53.3 57.1 74.8]\n",
      "vsa_grad_elsewhere_after4_transfer: [  1.5   nan   0.    5.2   6.3   4.3   6.4   6.    4.6   6.6   9.9   5.7\n",
      "   2.1   3.1   4.2   5.6   3.3   4.5   2.8   2.7   2.5   8.7   1.9   4.8\n",
      "   3.5   3.2   3.6   0.4   7.1   7.5   6.2   7.2   6.9   5.4   2.6   5.9\n",
      "   8.3   8.6   5.8   6.8   7.4   1.8   7.7   3.8  11.8   9.1   9.4  29.8\n",
      "   9.2   8.1   6.7   8.2   7.8  10.9   8.5  10.1   6.5  12.2  10.6   4.\n",
      "  12.4   5.1   0.5   1.   14.3   4.1   7.9   8.9   8.4   9.5   7.    8.8\n",
      "  15.5   7.6  10.8  11.2  12.    3.9   3.7   4.9   5.3   4.4   8.   13.4\n",
      "  13.2   4.7   7.3   6.1   9.7  10.3   9.6  25.3  21.5  13.3   5.   11.4\n",
      "  10.   11.7   9.3   3.  -13.4]\n",
      "vsa_enroll_after4_transfer: [40.9  nan  0.  23.  11.6 16.1 16.2 15.9  8.6 15.  14.7 11.4  4.6  7.6\n",
      "  7.  20.4 11.  10.3  9.8 10.2 16.3  7.2 14.6 12.5  8.   7.9 17.1  4.3\n",
      " 14.8 14.2 14.  13.9 20.3 14.3 16.5  5.8 18.8 11.1  5.2  8.5  7.7  4.2\n",
      "  3.6 11.2  7.8 13.3 13.6 11.8  3.2  5.9  7.5 17.7 11.5 21.8 24.1 19.3\n",
      " 10.1  8.3  9.5 13.5 18.9 12.8 12.  10.4 21.2 12.1  9.7 18.2 18.  13.8\n",
      " 18.3 22.6  5.3 12.7 11.9  9.3 15.4  6.7 13.   8.2 10.9 24.2 16.  17.8\n",
      " 13.4  8.9 15.5 10.8  7.1 15.2  6.5 11.3  8.4 16.7 19.8 19.5  4.1  2.5\n",
      "  6.6 20.9 18.6  2.1 64.5  5.5 15.8 19.9 22.4 14.1  5.6 12.3 20.6  7.3\n",
      " 13.2  6.4  1.9  3.9  8.1 18.4 17.4  6.3 21.4 10.7  1.5 13.7 16.6 14.9\n",
      " 20.2 15.7 27.7 15.3  6.   4.7 12.6 16.9 14.5 10.5 15.1 14.4 18.5 16.4\n",
      "  9. ]\n",
      "vsa_enroll_elsewhere_after4_transfer: [17.2  nan  0.   7.9  7.6  8.9 11.5  9.5  8.   6.5  7.1 13.1  2.4  9.8\n",
      "  4.7  4.9  5.   6.4  5.3  4.6  4.4 25.3  5.4  6.1  1.6  5.1  5.8  5.7\n",
      " 10.   6.9  8.6 11.  13.3 13.6  4.8  7.7  5.6  6.2  4.3  6.7  2.5 10.8\n",
      "  7.2  5.5  3.   3.7  7.3  9.7 12.4 15.  17.8 12.5 19.5  8.3 10.2  9.6\n",
      "  8.7 15.6 10.5  8.1  8.2 11.8 14.2 14.6 12.3 14.1  2.7  9.3 13.  19.\n",
      " 17.5  7.4 10.4  4.1  6.8 10.9  9.   9.1 11.6 11.1 10.3  4.  12.6  9.9\n",
      "  8.4 11.9 10.1  9.2  8.8  7.5  7.8  5.9  5.2 14.7  8.5 19.2 11.4 14.5\n",
      " 11.7 12.1  7.   3.9 11.2  9.4  1.8  3.8 18.9 11.3 17.3  0.7 12.  18.5\n",
      " 16.3  6.   3.1  4.2 13.5 10.7 25.1]\n",
      "vsa_grad_after6_transfer: [36.4  nan  0.  61.5 72.2 54.2 44.  32.9 68.2 59.1 53.  13.1 85.7 68.4\n",
      " 73.7 78.3 71.9 61.9 75.2 77.  80.3 55.7 78.1 67.6 79.7 79.9 64.3 74.3\n",
      " 60.6 53.4 67.2 63.6 50.8 29.3 57.  49.4 58.2 79.2 59.  55.2 52.8 68.1\n",
      " 66.7 76.4 81.3 77.7 67.9 62.9 64.1 82.3 64.6 82.8 84.  69.3 67.5 65.8\n",
      " 35.9 45.5 24.1 32.5 34.1 67.3 68.  64.8 51.  59.7 44.3 56.7 52.  33.8\n",
      " 57.3 49.  43.4 77.6 41.9 63.2 43.6 51.9 35.7 31.1 48.4 46.6 43.1 69.7\n",
      " 75.3 54.6 61.4 62.3 71.5 40.5 71.3 60.8 71.2 46.  56.9 80.8 73.4 60.3\n",
      " 61.7 63.  74.7 55.9 51.2 63.5 64.4 42.6 62.  58.8 70.3 58.9 62.1 43.3\n",
      " 46.5 49.3 59.5 52.6 49.8 48.3 55.1 76.9 67.4 70.6 59.4 50.2 78.6 75.9\n",
      " 63.4 74.8 64.2 54.5 39.8 59.3 84.8 63.7 58.3 73.8 54.8 48.9 50.  51.8\n",
      " 69.1 56.3 57.2 49.1 78.7 70.8 53.9 47.7 62.7 47.9 66.1 60.  64.5 62.2\n",
      " 89.3 74.  65.4 61.8 51.4 81.  45.9 54.7 22.7 72.9 53.5 42.4 69.2 64.7\n",
      " 47.8 58.1 41.  68.3 55.8 81.8 50.6 52.7 60.5 24.8 62.8 65.6 54.1 59.9\n",
      " 27.4 34.3 86.1 67.7 77.1 79.8 47.2 71.8 63.1 47.  47.3 78.9 56.4 62.5\n",
      " 57.1 75.7 60.2]\n",
      "vsa_grad_elsewhere_after6_transfer: [ 5.6  nan  0.   8.5  9.7  7.1  9.9 10.6  7.8  9.8 11.7  8.   3.4  7.2\n",
      "  4.4  6.9  7.7  5.1  5.8  4.   4.1  3.7 13.3  3.3  3.1  5.   4.5  0.6\n",
      " 10.2  9.6 11.6 11.5 11.   8.1  9.4  7.9  8.9  9.2  4.8  4.9  7.6 10.\n",
      " 12.5 10.8  7.3  2.8  6.2  6.4  8.3 15.8 13.8 13.1 30.9 16.3  9.3 10.1\n",
      " 11.1 12.6 12.3 14.3 12.7  9.5 15.3 14.4 16.6 13.  21.4 10.9  2.7  4.7\n",
      "  2.1 23.8  6.1 11.2  6.8 10.3  8.6 12.8 10.5 12.9 12.2 14.1 11.9 21.1\n",
      " 16.5 14.5 16.4 12.4 10.7 15.6  8.4  5.7  7.5  9.1 21.8 18.1 13.7 12.\n",
      " 12.1  6.5  5.5  8.8 15.2  3.2  8.7  5.3  7.   6.3 32.  23.2 19.  13.9\n",
      "  8.2 11.4 19.1 17.1  7.4 13.5 15.4 10.4 -9. ]\n",
      "vsa_enroll_after6_transfer: [17.2  nan  0.   6.3  2.   6.7  4.8  4.9  2.8  3.5  4.5  0.4  3.2  2.9\n",
      "  3.1  2.2  3.8  1.5  1.9  2.7  2.5  1.3  1.6  1.4  4.   3.7  4.1  7.\n",
      "  1.2  5.2  5.8  0.5  1.8  1.7  0.6  3.6  3.   1.   1.1  7.3  7.4 11.\n",
      "  7.5  6.5  2.4  4.4  6.1  4.6  3.3  5.1  5.9  6.   0.9  3.4  5.5  4.2\n",
      "  2.3  5.6  2.1  5.3  5.7  0.2  0.8  6.6  3.9  0.7  5.   4.7  6.9  7.2\n",
      "  4.3 13.9  2.6  6.4]\n",
      "vsa_enroll_elsewhere_after6_transfer: [11.1  nan  0.   5.5  4.6  7.6  9.5  7.4  2.9  5.3  4.7  1.   5.2  3.6\n",
      "  4.9  2.8  4.1  6.3  4.2  3.7 21.3  3.3  5.1  6.2  3.4  5.6  5.9  6.6\n",
      "  9.6  7.2  2.3  7.3  6.4  2.7  2.2  3.2  6.1  2.6  4.3  3.8  7.9 11.5\n",
      "  7.7 12.6 12.  10.6  5.7  4.5  6.9  8.8  6.5 11.7  5.8  8.1  4.4 10.4\n",
      " 11.4  7.1  9.7 10.   8.9  2.1  1.6 10.3  9.   4.8 17.2 10.8  7.8  8.5\n",
      "  7.   5.4  4.   8.   6.8  3.5 11.2  6.   1.8 11.3  7.5 13.7  9.1  5.\n",
      "  1.1  8.6 13.3  3.1  3.  11.8 10.7  8.2  9.4 14.6 12.1 10.1 11.9 17.3]\n",
      "similar: ['232937|100724|405997|113607|139533|144005|228501|101480|131876|144759|419509|176479|243197|228529|372222|228431|206695|139366|159993|224147'\n",
      " '196060|180461|201885|145600|209542|236939|126818|230764|104151|104179|157085|171100|153603|141574|155317|110714|137351|126562|243780|196088'\n",
      " '217925|441511|205124|247825|197647|221856|135364|117575|164207|193070|199315|166054|367893|183804|439701|193052|197744|193247|137777|176789'\n",
      " ...\n",
      " '446233|161208|454865|454616|444626|448239|447458|183150|244279|133155|446385|440624|188669|183123|450137|428000|447689|446774|449348|451769'\n",
      " '123581|448761|136747|450003|179052|446446|367097|440378|436702|451884|451963|451990|245962|133854|214528|144485|455619|447379|448497|443827'\n",
      " '454865|444626|454184|446233|448239|161208|447458|244279|133155|440624|183150|188669|183123|446385|447689|446774|451769|183114|450137|447263']\n",
      "state_sector_ct: [ 13  16  25   9   5   3   1   2  12   4  23  20  10  22  64 113  63  74\n",
      "  32  14  17  15   8  48  47  39  36  30  28   6  19  50  11  31  21   7\n",
      "  34  18 116  35  59  43  42  24  57  82  56  41  38  44  37]\n",
      "carnegie_ct: [386 106 252  96 289 343 124  99 128 111 125 169 517  81 114  83  54  33\n",
      "  31  79  47   7  73  43  42  34   4   5   1]\n",
      "counted_pct: ['99.7|07' '56.0|07' '100.0|07' ... '74.5|10' '3.6|10' '5.9|10']\n",
      "nicknames: [nan 'UAB' 'UAH' 'ASU' 'AUM' 'BSC' 'UNA' 'USA' 'UAA' 'U of A' 'NAU' 'WIU'\n",
      " 'UALR' 'UAPB' 'UAM' 'UCA' 'CIT|Caltech' 'Cal Poly'\n",
      " 'Cal State Bakersfield' 'Cal State Stanislaus' 'Cal State San Bernadino'\n",
      " 'Cal Poly Pomona' 'Cal State Chico' 'Cal State Dominguez Hills'\n",
      " 'Cal State Fresno' 'Cal State Fullerton' 'Cal State East Bay'\n",
      " 'Cal State Long Beach' 'CSULA| Cal State Los Angeles'\n",
      " 'Cal State Northridge' 'Cal State Sacramento' 'UCI' 'UCLA' 'UCR' 'UCSD'\n",
      " 'UCSB' 'UCSC' 'CMC' 'LMU' 'Oxy' 'PLNU' 'SDSU' 'USD' 'SFSU' 'USFCA|USF'\n",
      " 'SJSU' 'SCU' 'USC' 'UCD' 'CSU' 'Metro State' 'UNC' 'CSU Pueblo' 'CCSU'\n",
      " 'UConn' 'UNH' 'SCSU' 'UDel' 'UDC' 'GWU' 'UCF|Florida Tech' 'FAMU' 'FAU'\n",
      " 'FIU' 'FSU' 'The U' 'UNF' 'NSU' 'USF' 'UWF' 'GIT|Georgia Tech' 'GC&SU'\n",
      " 'GSU' 'UGA' 'SSU' 'VSU' 'BSU' 'ISU' 'U of I' 'UIC' 'UIUC|U of I' 'IIT'\n",
      " 'LUC' 'NIU' 'SIU|SIUC' 'SIUE' 'IPFW' 'IUPUI' 'USI' 'IUB' 'Valpo' 'UNI'\n",
      " 'KSU|K-State' 'WSU' 'KSU' 'WKU' 'LSU Alexandria' 'LSU' 'LSU Shreveport'\n",
      " 'XULA' 'USM' 'JHU' 'UMBC' 'SJC' 'ENC' 'UML' 'UMass' 'UMB' 'MIT'\n",
      " 'MHC|MoHo' 'MCLA' 'WPI' 'UDM' 'EMU' 'GVSU' 'LSSU' 'MSU' 'MTU' 'NMU' 'WMU'\n",
      " 'CSB' 'Ole Miss' 'MUW' 'MVSU' 'Mizzou' 'UMKC' 'Missouri S&T|MUST' 'UMSL'\n",
      " 'SLU' 'SEMo' 'Wash U|WUSTL' 'MSU Bozeman' 'UNO' 'UNL' 'UNLV' 'UNR' 'FDU'\n",
      " 'CSE' 'TCNJ|Trenton State' 'UNM' 'NMSU' 'CUNY Baruch' 'CUNY Brooklyn'\n",
      " 'CUNY Staten Island' 'CCNY|CUNY City College'\n",
      " 'CUNY John Jay College of Criminal Justice' 'CUNY Medgar Evers'\n",
      " 'City Tech' 'CUNY Queens' 'CUNY York' 'LIU Brooklyn' 'LIU' 'NYU' 'RPI'\n",
      " 'RIT' 'U of R' 'SUNY' 'SUNY Albany' 'SUNY Buffalo' 'SUNY Stony Brook'\n",
      " 'SUNY Utica|SUNY Tech' 'SUNY Brockport' 'SUNY Cortland' 'SUNY Fredonia'\n",
      " 'SUNY Geneseo' 'SUNY New Paltz' 'SUNY Oneonta' 'SUNY Oswego'\n",
      " 'SUNY Potsdam' 'SUNY Purchase' 'SUNY Old Westbury' 'SUNY Plattsburgh'\n",
      " 'SUNY Empire State College' 'SUNY Maritime College' 'ECU' 'A&T|NC A&T'\n",
      " 'Central|NCCU' 'UNCW' 'WFU' 'UND' 'NDSU' 'ODU' 'ONU' 'OSU' 'YSU' 'UCO'\n",
      " 'OCU' 'ORU' 'USAO' 'OIT' 'Nike' 'PSU' 'Cal U|CUP' 'CMU' 'F&M' 'IUP' 'LHU'\n",
      " 'Penn State Erie' 'Penn State New Kensington' 'Penn State Shenango'\n",
      " 'Penn State Wilkes-Barre' 'Penn State Worthington-Scranton'\n",
      " 'Penn State Lehigh Valley' 'Penn State Altoona' 'Penn State Beaver'\n",
      " 'Penn State Berks' 'Penn State Harrisburg' 'Penn State Brandywine'\n",
      " 'Penn State DuBois' 'Penn State Fayette' 'Penn State Hazleton'\n",
      " 'Penn State|PSU' 'Penn State Greater Allegheny' 'Penn State Mont Alto'\n",
      " 'Penn State Abington' 'Penn State Schuylkill' 'Penn State York' 'Penn'\n",
      " 'Pitt' 'U of S' 'SRU' 'W&J' 'RIC' 'URI' 'RWU' 'BJU' 'C of C' 'USCA' 'CCU'\n",
      " 'ETSU' 'MTSU' 'Vandy' 'UHD' 'U of H' 'UNT' 'UTB|TSC' 'PVAMU' 'SMU' 'TxSt'\n",
      " 'TAMU' 'UTA' 'UTD' 'UTEP' 'TCU' 'UTPB' 'UTSA' 'TTU' 'WTAMU' 'BYU' 'SUU'\n",
      " 'UVU' 'UVM' 'W&M' 'CNU' 'GMU' 'HIU' 'JMU' 'RMC' 'VPI' 'VCU' 'UVA' 'W&L'\n",
      " 'EWU' 'SPU' 'U Dub' 'WVU' 'UWGB' 'UWM' 'JSU' 'NCF' 'Cal State San Marcos'\n",
      " 'Cal State Monterey Bay' 'JWU' 'FGCU' 'Cal State Channel Islands']\n",
      "cohort_size: [ 882. 1376.    3. ...  925.   44. 1021.]\n",
      "unitid                0\n",
      "chronname             0\n",
      "city                  0\n",
      "state                 0\n",
      "level                 0\n",
      "                   ... \n",
      "state_sector_ct       0\n",
      "carnegie_ct           0\n",
      "counted_pct         378\n",
      "nicknames          3225\n",
      "cohort_size         155\n",
      "Length: 62, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for unusual strings that might represent missing data\n",
    "for column in grad_data.columns:\n",
    "    print(f\"{column}: {grad_data[column].unique()}\")\n",
    "\n",
    "# Convert potential string-encoded missing values to NaN\n",
    "grad_data.replace(['NA', 'na', 'null', 'None', 'NaN', \" \"], pd.NA, inplace=True)\n",
    "\n",
    "# Now check again for any NaNs\n",
    "print(grad_data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count per Column:\n",
      "unitid                0\n",
      "chronname             0\n",
      "city                  0\n",
      "state                 0\n",
      "level                 0\n",
      "                   ... \n",
      "state_sector_ct       0\n",
      "carnegie_ct           0\n",
      "counted_pct         378\n",
      "nicknames          3225\n",
      "cohort_size         155\n",
      "Length: 62, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List column names that have missing values\n",
    "missing_values_count = grad_data.isna().sum()\n",
    "print(\"Missing Values Count per Column:\")\n",
    "print(missing_values_count)\n",
    "columns_with_na = missing_values_count[missing_values_count > 0].index.tolist()\n",
    "grad_data = grad_data.drop(columns = columns_with_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chronname', 'city', 'state', 'basic'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "objects = grad_data.dtypes[grad_data.dtypes == \"object\"].index\n",
    "print(objects)\n",
    "grad_data = grad_data.drop(columns = objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unitid                    False\n",
      "level                     False\n",
      "Institutional_Type        False\n",
      "long_x                    False\n",
      "lat_y                     False\n",
      "student_count             False\n",
      "awards_per_value          False\n",
      "awards_per_state_value    False\n",
      "awards_per_natl_value     False\n",
      "exp_award_value           False\n",
      "exp_award_state_value     False\n",
      "exp_award_natl_value      False\n",
      "exp_award_percentile      False\n",
      "ft_pct                    False\n",
      "fte_value                 False\n",
      "fte_percentile            False\n",
      "retain_value              False\n",
      "retain_percentile         False\n",
      "state_sector_ct           False\n",
      "carnegie_ct               False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(grad_data.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fb2f7346690>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 709.875x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Missing Data? \n",
    "sns.displot(\n",
    "    data=grad_data.isna().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "\n",
    "#No Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unitid', 'student_count', 'exp_award_value', 'exp_award_state_value',\n",
      "       'exp_award_natl_value', 'exp_award_percentile', 'fte_value',\n",
      "       'fte_percentile', 'state_sector_ct', 'carnegie_ct'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = grad_data.select_dtypes(include='int64').columns\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "d = scaler.fit_transform(grad_data[numeric_cols])   # conduct data transformation\n",
    "scaled_df = pd.DataFrame(d, columns=numeric_cols)   # convert back to pd df; transformation converts to array\n",
    "grad_data[numeric_cols] = scaled_df   # put data back into the main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unitid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "long_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "student_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "awards_per_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "awards_per_state_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "awards_per_natl_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exp_award_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exp_award_state_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exp_award_natl_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exp_award_percentile",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ft_pct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fte_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fte_percentile",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "retain_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "retain_percentile",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "state_sector_ct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "carnegie_ct",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9b9c0de0-333a-41b6-801a-cac85152f497",
       "rows": [
        [
         "count",
         "3326.0",
         "3535.0",
         "3535.0",
         "3326.0",
         "3535.0",
         "3535.0",
         "3535.0",
         "3326.0",
         "3326.0",
         "3326.0",
         "3326.0",
         "3535.0",
         "3326.0",
         "3326.0",
         "3535.0",
         "3535.0",
         "3326.0",
         "3326.0"
        ],
        [
         "mean",
         "0.31309011349417787",
         "-90.87302833154173",
         "38.209036796322486",
         "0.027451374737438396",
         "22.84435643564356",
         "22.720537482319664",
         "22.377369165487977",
         "0.01279020283546237",
         "0.2851047678212409",
         "0.486697612428351",
         "0.5135838845460012",
         "71.45159830268742",
         "0.030548979106643455",
         "0.5088995790739627",
         "66.23185289957567",
         "49.22659123055163",
         "0.29473450286281994",
         "0.4580757899938003"
        ],
        [
         "std",
         "0.26196429975931",
         "15.698246562260277",
         "4.967600587728566",
         "0.043960015457004106",
         "10.158918135728046",
         "6.407893604511647",
         "4.909072181295111",
         "0.02145066815202532",
         "0.19259195937151638",
         "0.39367588523977254",
         "0.2889004720240221",
         "25.16523981572411",
         "0.048278104062438536",
         "0.28957618627395043",
         "17.03390684123977",
         "29.175248153482727",
         "0.25004200602605364",
         "0.29800088506654354"
        ],
        [
         "min",
         "0.0",
         "-159.395966",
         "19.69972",
         "0.0",
         "0.5",
         "3.2",
         "16.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.8",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.005813953488372093"
        ],
        [
         "25%",
         "0.14505767889542978",
         "-97.2282855",
         "34.439137",
         "0.00393837327549215",
         "17.0",
         "19.0",
         "16.5",
         "0.006363999511557441",
         "0.13991298633613558",
         "0.16878980891719747",
         "0.27",
         "49.8",
         "0.005469702005095823",
         "0.26",
         "56.1",
         "24.0",
         "0.11304347826086956",
         "0.20348837209302326"
        ],
        [
         "50%",
         "0.25496690511374115",
         "-86.799304",
         "39.054414",
         "0.011383074399985893",
         "21.1",
         "22.0",
         "22.5",
         "0.009964417527515125",
         "0.2405565248917994",
         "0.1815676589106981",
         "0.52",
         "78.0",
         "0.013491272215100727",
         "0.51",
         "66.9",
         "49.0",
         "0.20869565217391303",
         "0.3255813953488372"
        ],
        [
         "75%",
         "0.3416195250476315",
         "-79.6948755",
         "41.638864",
         "0.032227061914754794",
         "25.6",
         "24.2",
         "22.5",
         "0.0151145994155728",
         "0.3821010174253926",
         "1.0",
         "0.76",
         "94.4",
         "0.03518017376442103",
         "0.76",
         "78.1",
         "75.0",
         "0.40869565217391307",
         "0.6627906976744186"
        ],
        [
         "max",
         "0.9999999999999999",
         "-67.243306",
         "71.324702",
         "1.0",
         "131.1",
         "59.9",
         "32.8",
         "1.0",
         "0.9999999999999999",
         "1.0",
         "1.0",
         "100.0",
         "0.9999999999999999",
         "1.0",
         "100.0",
         "100.0",
         "1.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unitid</th>\n",
       "      <th>long_x</th>\n",
       "      <th>lat_y</th>\n",
       "      <th>student_count</th>\n",
       "      <th>awards_per_value</th>\n",
       "      <th>awards_per_state_value</th>\n",
       "      <th>awards_per_natl_value</th>\n",
       "      <th>exp_award_value</th>\n",
       "      <th>exp_award_state_value</th>\n",
       "      <th>exp_award_natl_value</th>\n",
       "      <th>exp_award_percentile</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>fte_value</th>\n",
       "      <th>fte_percentile</th>\n",
       "      <th>retain_value</th>\n",
       "      <th>retain_percentile</th>\n",
       "      <th>state_sector_ct</th>\n",
       "      <th>carnegie_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "      <td>3326.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.313090</td>\n",
       "      <td>-90.873028</td>\n",
       "      <td>38.209037</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>22.844356</td>\n",
       "      <td>22.720537</td>\n",
       "      <td>22.377369</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.285105</td>\n",
       "      <td>0.486698</td>\n",
       "      <td>0.513584</td>\n",
       "      <td>71.451598</td>\n",
       "      <td>0.030549</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>66.231853</td>\n",
       "      <td>49.226591</td>\n",
       "      <td>0.294735</td>\n",
       "      <td>0.458076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.261964</td>\n",
       "      <td>15.698247</td>\n",
       "      <td>4.967601</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>10.158918</td>\n",
       "      <td>6.407894</td>\n",
       "      <td>4.909072</td>\n",
       "      <td>0.021451</td>\n",
       "      <td>0.192592</td>\n",
       "      <td>0.393676</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>25.165240</td>\n",
       "      <td>0.048278</td>\n",
       "      <td>0.289576</td>\n",
       "      <td>17.033907</td>\n",
       "      <td>29.175248</td>\n",
       "      <td>0.250042</td>\n",
       "      <td>0.298001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-159.395966</td>\n",
       "      <td>19.699720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.145058</td>\n",
       "      <td>-97.228285</td>\n",
       "      <td>34.439137</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.168790</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.203488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.254967</td>\n",
       "      <td>-86.799304</td>\n",
       "      <td>39.054414</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.009964</td>\n",
       "      <td>0.240557</td>\n",
       "      <td>0.181568</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>66.900000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>0.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.341620</td>\n",
       "      <td>-79.694875</td>\n",
       "      <td>41.638864</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.382101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>94.400000</td>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>78.100000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.662791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-67.243306</td>\n",
       "      <td>71.324702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>131.100000</td>\n",
       "      <td>59.900000</td>\n",
       "      <td>32.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            unitid       long_x        lat_y  student_count  awards_per_value  \\\n",
       "count  3326.000000  3535.000000  3535.000000    3326.000000       3535.000000   \n",
       "mean      0.313090   -90.873028    38.209037       0.027451         22.844356   \n",
       "std       0.261964    15.698247     4.967601       0.043960         10.158918   \n",
       "min       0.000000  -159.395966    19.699720       0.000000          0.500000   \n",
       "25%       0.145058   -97.228285    34.439137       0.003938         17.000000   \n",
       "50%       0.254967   -86.799304    39.054414       0.011383         21.100000   \n",
       "75%       0.341620   -79.694875    41.638864       0.032227         25.600000   \n",
       "max       1.000000   -67.243306    71.324702       1.000000        131.100000   \n",
       "\n",
       "       awards_per_state_value  awards_per_natl_value  exp_award_value  \\\n",
       "count             3535.000000            3535.000000      3326.000000   \n",
       "mean                22.720537              22.377369         0.012790   \n",
       "std                  6.407894               4.909072         0.021451   \n",
       "min                  3.200000              16.500000         0.000000   \n",
       "25%                 19.000000              16.500000         0.006364   \n",
       "50%                 22.000000              22.500000         0.009964   \n",
       "75%                 24.200000              22.500000         0.015115   \n",
       "max                 59.900000              32.800000         1.000000   \n",
       "\n",
       "       exp_award_state_value  exp_award_natl_value  exp_award_percentile  \\\n",
       "count            3326.000000           3326.000000           3326.000000   \n",
       "mean                0.285105              0.486698              0.513584   \n",
       "std                 0.192592              0.393676              0.288900   \n",
       "min                 0.000000              0.000000              0.000000   \n",
       "25%                 0.139913              0.168790              0.270000   \n",
       "50%                 0.240557              0.181568              0.520000   \n",
       "75%                 0.382101              1.000000              0.760000   \n",
       "max                 1.000000              1.000000              1.000000   \n",
       "\n",
       "            ft_pct    fte_value  fte_percentile  retain_value  \\\n",
       "count  3535.000000  3326.000000     3326.000000   3535.000000   \n",
       "mean     71.451598     0.030549        0.508900     66.231853   \n",
       "std      25.165240     0.048278        0.289576     17.033907   \n",
       "min       3.800000     0.000000        0.000000      0.000000   \n",
       "25%      49.800000     0.005470        0.260000     56.100000   \n",
       "50%      78.000000     0.013491        0.510000     66.900000   \n",
       "75%      94.400000     0.035180        0.760000     78.100000   \n",
       "max     100.000000     1.000000        1.000000    100.000000   \n",
       "\n",
       "       retain_percentile  state_sector_ct  carnegie_ct  \n",
       "count        3535.000000      3326.000000  3326.000000  \n",
       "mean           49.226591         0.294735     0.458076  \n",
       "std            29.175248         0.250042     0.298001  \n",
       "min             0.000000         0.000000     0.005814  \n",
       "25%            24.000000         0.113043     0.203488  \n",
       "50%            49.000000         0.208696     0.325581  \n",
       "75%            75.000000         0.408696     0.662791  \n",
       "max           100.000000         1.000000     1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "level_2-year",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "level_4-year",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Institutional_Type_Private",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Institutional_Type_Public",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ecf44592-355b-4b0e-bdeb-e3c70b83c40d",
       "rows": [
        [
         "0",
         "False",
         "True",
         "False",
         "True"
        ],
        [
         "1",
         "False",
         "True",
         "False",
         "True"
        ],
        [
         "2",
         "False",
         "True",
         "True",
         "False"
        ],
        [
         "3",
         "False",
         "True",
         "False",
         "True"
        ],
        [
         "4",
         "False",
         "True",
         "False",
         "True"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_2-year</th>\n",
       "      <th>level_4-year</th>\n",
       "      <th>Institutional_Type_Private</th>\n",
       "      <th>Institutional_Type_Public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_2-year  level_4-year  Institutional_Type_Private  \\\n",
       "0         False          True                       False   \n",
       "1         False          True                       False   \n",
       "2         False          True                        True   \n",
       "3         False          True                       False   \n",
       "4         False          True                       False   \n",
       "\n",
       "   Institutional_Type_Public  \n",
       "0                       True  \n",
       "1                       True  \n",
       "2                      False  \n",
       "3                       True  \n",
       "4                       True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = grad_data.select_dtypes(include='category').columns\n",
    "encoded = pd.get_dummies(grad_data[cat_cols])\n",
    "encoded.head()   \n",
    "#I realized that other object variables had too many value counts so I decided to only one hot encode\n",
    "#level and Institutional Type column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data = grad_data.drop(cat_cols, axis=1)\n",
    "grad_data = grad_data.join(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3535 entries, 0 to 3796\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   unitid                      3326 non-null   float64\n",
      " 1   long_x                      3535 non-null   float64\n",
      " 2   lat_y                       3535 non-null   float64\n",
      " 3   student_count               3326 non-null   float64\n",
      " 4   awards_per_value            3535 non-null   float64\n",
      " 5   awards_per_state_value      3535 non-null   float64\n",
      " 6   awards_per_natl_value       3535 non-null   float64\n",
      " 7   exp_award_value             3326 non-null   float64\n",
      " 8   exp_award_state_value       3326 non-null   float64\n",
      " 9   exp_award_natl_value        3326 non-null   float64\n",
      " 10  exp_award_percentile        3326 non-null   float64\n",
      " 11  ft_pct                      3535 non-null   float64\n",
      " 12  fte_value                   3326 non-null   float64\n",
      " 13  fte_percentile              3326 non-null   float64\n",
      " 14  retain_value                3535 non-null   float64\n",
      " 15  retain_percentile           3535 non-null   float64\n",
      " 16  state_sector_ct             3326 non-null   float64\n",
      " 17  carnegie_ct                 3326 non-null   float64\n",
      " 18  level_2-year                3535 non-null   bool   \n",
      " 19  level_4-year                3535 non-null   bool   \n",
      " 20  Institutional_Type_Private  3535 non-null   bool   \n",
      " 21  Institutional_Type_Public   3535 non-null   bool   \n",
      "dtypes: bool(4), float64(18)\n",
      "memory usage: 538.5 KB\n"
     ]
    }
   ],
   "source": [
    "grad_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data = grad_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unitid                        0\n",
      "long_x                        0\n",
      "lat_y                         0\n",
      "student_count                 0\n",
      "awards_per_value              0\n",
      "awards_per_state_value        0\n",
      "awards_per_natl_value         0\n",
      "exp_award_value               0\n",
      "exp_award_state_value         0\n",
      "exp_award_natl_value          0\n",
      "exp_award_percentile          0\n",
      "ft_pct                        0\n",
      "fte_value                     0\n",
      "fte_percentile                0\n",
      "retain_value                  0\n",
      "retain_percentile             0\n",
      "state_sector_ct               0\n",
      "carnegie_ct                   0\n",
      "level_2-year                  0\n",
      "level_4-year                  0\n",
      "Institutional_Type_Private    0\n",
      "Institutional_Type_Public     0\n",
      "dtype: int64\n",
      "Total missing values in the DataFrame: 0\n"
     ]
    }
   ],
   "source": [
    "# Using isna() and sum() to count missing values per column\n",
    "missing_values_per_column = grad_data.isna().sum()\n",
    "\n",
    "# Print the counts of missing values per column\n",
    "print(missing_values_per_column)\n",
    "\n",
    "# If you want to check the total number of missing values in the DataFrame\n",
    "total_missing_values = grad_data.isna().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build a kNN model to predict your target variable using 3 nearest neighbors. Make sure it is a classification problem, meaning if needed changed the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42408/4220521448.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  grad_data['Institutional_Type_Public'].value_counts()[1] / grad_data['Institutional_Type_Public'].count()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.45009019843656045)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_data['Institutional_Type_Public'].value_counts()[1] / grad_data['Institutional_Type_Public'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X = grad_data.drop(['Institutional_Type_Public'], axis=1).values   # independent variables\n",
    "y = grad_data['Institutional_Type_Public'].values                  # dependent variable\n",
    "\"\"\"\n",
    "\n",
    "train, test = train_test_split(grad_data,  test_size=0.4, stratify = grad_data['Institutional_Type_Public']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, val = train_test_split(test, test_size=0.5, stratify=test['Institutional_Type_Public'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unitid', 'long_x', 'lat_y', 'student_count', 'awards_per_value',\n",
      "       'awards_per_state_value', 'awards_per_natl_value', 'exp_award_value',\n",
      "       'exp_award_state_value', 'exp_award_natl_value', 'exp_award_percentile',\n",
      "       'ft_pct', 'fte_value', 'fte_percentile', 'retain_value',\n",
      "       'retain_percentile', 'state_sector_ct', 'carnegie_ct', 'level_2-year',\n",
      "       'level_4-year', 'Institutional_Type_Private',\n",
      "       'Institutional_Type_Public'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(grad_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.seed(330)\n",
    "\n",
    "X_train = train.drop(['Institutional_Type_Public'], axis=1).values\n",
    "y_train = train['Institutional_Type_Public'].values\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825563909774436"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of the Test Data\n",
    "X_test = test.drop(['Institutional_Type_Public'], axis=1).values\n",
    "y_test = test['Institutional_Type_Public'].values\n",
    "\n",
    "neigh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753753753753754"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of Validation Data\n",
    "X_val = val.drop(['Institutional_Type_Public'], axis=1).values\n",
    "y_val = val['Institutional_Type_Public'].values\n",
    "\n",
    "neigh.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a dataframe that includes the test target values, test predicted values, and test probabilities of the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(X_test)\n",
    "y_probs = neigh.predict_proba(X_test)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Actual  Predicted  Probabilities\n",
      "0    True       True       0.666667\n",
      "1    True       True       1.000000\n",
      "2   False      False       0.000000\n",
      "3   False      False       0.000000\n",
      "4   False      False       0.000000\n"
     ]
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame({\n",
    "    \"Actual\": y_test,\n",
    "    \"Predicted\": y_pred,\n",
    "    \"Probabilities\" : y_probs\n",
    "})\n",
    "\n",
    "print(accuracy_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. No code question: If you adjusted the k hyperparameter what do you think would happen to the threshold function? Would the confusion look the same at the same threshold levels or not? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I adjust the k hyperparameter, it would significantly impact the data. If the k value gets larger, it will reduce the variance of the predictions and make the model more reliable, but it will underfit the data. If k value gets too small, it will overfit the data as it will be more sensitive to the noise of the data. If the k value is small, sensitivity(True Positive) will increase yet the specificity(True Negative) will decrease and vice versa if the k value is large. Due to these reason, if k changes, the confusion will not look the same and the values will be adjusted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate the results using the confusion matrix. Then \"walk\" through your question, summarize what concerns or positive elements do you have about the model as it relates to your question? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_pred, labels=neigh.classes_)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=neigh.classes_)  \n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782608695652174 0.8469945355191257\n"
     ]
    }
   ],
   "source": [
    "sensitivity = 234/(234+65)   # = TP/(TP+FN)\n",
    "specificity = 310/(310+56)   # = TN/(TN+FP)\n",
    "print(sensitivity, specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the kNN model enhanced the accuracy of predicting, I believe that the value could be more increased. (Sensitivity is around 0.78 and specificity is around 0.85) The fact that the specificity is higher than the sensitivity could mean k value is too large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create two functions: One that cleans the data & splits into training|test and one that allows you to train and test the model with different k and threshold values, then use them to optimize your model (test your model with several k and threshold combinations). Try not to use variable names in the functions, but if you need to that's fine. (If you can't get the k function and threshold function to work in one function just run them separately.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split_data(df, target, test_size=0.4, val_size=0.5, random_state=330):\n",
    "\n",
    "    # Rename and recategorize 'control' to 'Institutional_Type'\n",
    "    df.rename(columns={\"control\": \"Institutional_Type\"}, inplace=True)\n",
    "    Private = [\"Private not-for-profit\", \"Private for-profit\"]\n",
    "    df['Institutional_Type'] = df['Institutional_Type'].apply(lambda x: \"Private\" if x in Private else \"Public\")\n",
    "\n",
    "    # Convert specified categories to type \"category\"\n",
    "    cat_cols = [\"level\", \"Institutional_Type\"]\n",
    "    df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "\n",
    "    # Drop columns with dtype 'object' that are not in 'cat_cols'\n",
    "    df = df.drop(columns=df.select_dtypes(include='object').columns.difference(cat_cols))\n",
    "\n",
    "    # Convert potential string-encoded missing values to NaN\n",
    "    df.replace(['NA', 'na', 'null', 'None', 'NaN', \" \"], pd.NA, inplace=True)\n",
    "    missing_values_count = df.isna().sum()\n",
    "    columns_with_na = missing_values_count[missing_values_count > 0].index.tolist()\n",
    "    df = df.drop(columns = columns_with_na)\n",
    "\n",
    "\n",
    "    # Normalize numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    scaler = MinMaxScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "    target_columns = [col for col in df.columns if col.startswith(target)]\n",
    "\n",
    "    X = df.drop(target_columns, axis=1)\n",
    "    y = df[target_columns]  # Adjust based on the specific target column needed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    k_values = range(1, 22, 2)\n",
    "    accuracies = []\n",
    "    \n",
    "    # Loop over k values\n",
    "    for k in k_values:\n",
    "        print(f\"Calculating for k = {k}\") \n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        accuracy = knn.score(X_test, y_test)  \n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    # Create a DataFrame with k values and their corresponding accuracies\n",
    "    results_df = pd.DataFrame({\n",
    "        'k': k_values,\n",
    "        'Accuracy': accuracies\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Institutional_Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Institutional_Type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mclean_and_split_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInstitutional_Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m results_df \u001b[38;5;241m=\u001b[39m evaluate_knn(X_train, y_train\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel(), X_test, y_test\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel()) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m, in \u001b[0;36mclean_and_split_data\u001b[0;34m(df, target, test_size, val_size, random_state)\u001b[0m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstitutional_Type\u001b[39m\u001b[38;5;124m\"\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m Private \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrivate not-for-profit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrivate for-profit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstitutional_Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInstitutional_Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrivate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m Private \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPublic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert specified categories to type \"category\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstitutional_Type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Institutional_Type'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = clean_and_split_data(grad_data, \"Institutional_Type\")\n",
    "results_df = evaluate_knn(X_train, y_train.values.ravel(), X_test, y_test.values.ravel()) \n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. How well does the model perform? Did the interaction of the adjusted thresholds and k values help the model? Why or why not? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that the function had some problems on cleaning the data. When I run the model with k=3, the accuracy of validation data was around 0.86. With the function, the fact that I got 1.0 for all k values means that my kNN model is performing exceptionally well across all of these k values which I highly doubt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating...  1 k\n",
      "calculating...  3 k\n",
      "calculating...  5 k\n",
      "calculating...  7 k\n",
      "calculating...  9 k\n",
      "calculating...  11 k\n",
      "calculating...  13 k\n",
      "calculating...  15 k\n",
      "calculating...  17 k\n",
      "calculating...  19 k\n",
      "calculating...  21 k\n"
     ]
    }
   ],
   "source": [
    "def chooseK(k, X_train, y_train, X_test, y_test):\n",
    "    random.seed(1)\n",
    "    print(\"calculating... \", k, \"k\")    # I'll include this so you can see the progress of the function as it runs\n",
    "    class_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    class_knn.fit(X_train, y_train)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accu = class_knn.score(X_test, y_test)\n",
    "    return accu\n",
    "\n",
    "test = pd.DataFrame({'k':list(range(1,22,2)), \n",
    "    'accu':[chooseK(x, X_train, y_train, X_test, y_test) for x in list(range(1, 22, 2))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "k",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "accu",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "208e5a63-3c95-4ee1-9c06-7a2928f648a2",
       "rows": [
        [
         "0",
         "1",
         "0.8406015037593985"
        ],
        [
         "1",
         "3",
         "0.825563909774436"
        ],
        [
         "2",
         "5",
         "0.8180451127819549"
        ],
        [
         "3",
         "7",
         "0.8165413533834587"
        ],
        [
         "4",
         "9",
         "0.8315789473684211"
        ],
        [
         "5",
         "11",
         "0.8315789473684211"
        ],
        [
         "6",
         "13",
         "0.8285714285714286"
        ],
        [
         "7",
         "15",
         "0.8390977443609022"
        ],
        [
         "8",
         "17",
         "0.8406015037593985"
        ],
        [
         "9",
         "19",
         "0.8345864661654135"
        ],
        [
         "10",
         "21",
         "0.8345864661654135"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.840602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.818045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.816541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.831579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.831579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.839098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.840602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.834586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>0.834586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k      accu\n",
       "0    1  0.840602\n",
       "1    3  0.825564\n",
       "2    5  0.818045\n",
       "3    7  0.816541\n",
       "4    9  0.831579\n",
       "5   11  0.831579\n",
       "6   13  0.828571\n",
       "7   15  0.839098\n",
       "8   17  0.840602\n",
       "9   19  0.834586\n",
       "10  21  0.834586"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using the function, when I run through the various k values, it seems like k=1 has the highest accuracy. This means that the noise or outliers do not exist or does not significantly impact the model and the data points are very close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Choose another variable as the target in the dataset and create another kNN model using the two functions you created in step 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for k = 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2278, 4556]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m clean_and_split_data(grad_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_knn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n",
      "Cell \u001b[0;32mIn[35], line 10\u001b[0m, in \u001b[0;36mevaluate_knn\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating for k = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m      9\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)  \n\u001b[1;32m     12\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:239\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# KNeighborsClassifier.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    220\u001b[0m )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/neighbors/_base.py:478\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_tags__()\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 478\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m            \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;66;03m# Classification targets require a specific format\u001b[39;00m\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:1389\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1371\u001b[0m     X,\n\u001b[1;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1385\u001b[0m )\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2278, 4556]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = clean_and_split_data(grad_data, \"level\")\n",
    "results_df = evaluate_knn(X_train, y_train.values.ravel(), X_test, y_test.values.ravel()) \n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
